From d26025af989c466209c73a3d3132a84893231f97 Mon Sep 17 00:00:00 2001
From: Yichao Yu <yyc1992@gmail.com>
Date: Thu, 29 Jun 2017 04:28:06 -0400
Subject: [PATCH 8/9] Implement function multi versioning in sysimg

* Implementing function cloning pass.
* Hook up debug info lookup and sysimg loading to the processor initialization API.
---
 src/Makefile                 |    6 +-
 src/anticodegen.c            |    4 +-
 src/debuginfo.cpp            |   27 +-
 src/jitlayers.cpp            |   30 +-
 src/jitlayers.h              |    3 +-
 src/julia_internal.h         |    4 +-
 src/llvm-multiversioning.cpp | 1067 ++++++++++++++++++++++++++++++++++++++++++
 src/processor.h              |    2 +-
 src/staticdata.c             |   41 +-
 9 files changed, 1135 insertions(+), 49 deletions(-)
 create mode 100644 src/llvm-multiversioning.cpp

diff --git a/src/Makefile b/src/Makefile
index db1ac4fd6f..0bbbedba99 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -52,7 +52,7 @@ LLVMLINK :=
 ifeq ($(JULIACODEGEN),LLVM)
 SRCS += codegen jitlayers disasm debuginfo llvm-simdloop llvm-ptls llvm-muladd \
 	llvm-late-gc-lowering llvm-lower-handlers llvm-gc-invariant-verifier \
-	llvm-propagate-addrspaces llvm-alloc-opt cgmemmgr
+	llvm-propagate-addrspaces llvm-multiversioning llvm-alloc-opt cgmemmgr
 FLAGS += -I$(shell $(LLVM_CONFIG_HOST) --includedir)
 LLVM_LIBS := all
 ifeq ($(USE_POLLY),1)
@@ -185,10 +185,12 @@ $(BUILDDIR)/codegen.o $(BUILDDIR)/codegen.dbg.obj: $(addprefix $(SRCDIR)/,\
 	intrinsics.cpp jitlayers.h intrinsics.h debuginfo.h codegen_shared.h cgutils.cpp ccall.cpp abi_*.cpp processor.h)
 $(BUILDDIR)/processor.o $(BUILDDIR)/processor.dbg.obj: $(addprefix $(SRCDIR)/,processor_*.cpp processor.h features_*.h)
 $(BUILDDIR)/anticodegen.o $(BUILDDIR)/anticodegen.dbg.obj: $(SRCDIR)/intrinsics.h
-$(BUILDDIR)/debuginfo.o $(BUILDDIR)/debuginfo.dbg.obj: $(SRCDIR)/debuginfo.h
+$(BUILDDIR)/debuginfo.o $(BUILDDIR)/debuginfo.dbg.obj: \
+	$(addprefix $(SRCDIR)/,debuginfo.h processor.h)
 $(BUILDDIR)/disasm.o $(BUILDDIR)/disasm.dbg.obj: $(SRCDIR)/debuginfo.h $(SRCDIR)/processor.h
 $(BUILDDIR)/jitlayers.o $(BUILDDIR)/jitlayers.dbg.obj: $(SRCDIR)/jitlayers.h
 $(BUILDDIR)/builtins.o $(BUILDDIR)/builtins.dbg.obj: $(SRCDIR)/table.c
+$(BUILDDIR)/staticdata.o $(BUILDDIR)/staticdata.dbg.obj: $(SRCDIR)/processor.h
 $(BUILDDIR)/gc.o $(BUILDDIR)/gc.dbg.obj: $(SRCDIR)/gc.h
 $(BUILDDIR)/gc-debug.o $(BUILDDIR)/gc-debug.dbg.obj: $(SRCDIR)/gc.h
 $(BUILDDIR)/gc-pages.o $(BUILDDIR)/gc-pages.dbg.obj: $(SRCDIR)/gc.h
diff --git a/src/anticodegen.c b/src/anticodegen.c
index b19afe21d5..8c87d30640 100644
--- a/src/anticodegen.c
+++ b/src/anticodegen.c
@@ -36,10 +36,10 @@ int jl_getFunctionInfo(jl_frame_t **frames, uintptr_t pointer, int skipC, int no
     return 0;
 }
 
-void jl_register_fptrs(uint64_t sysimage_base, const char *base, const int32_t *offsets,
+void jl_register_fptrs(uint64_t sysimage_base, const struct _jl_sysimg_fptrs_t *fptrs,
                        jl_method_instance_t **linfos, size_t n)
 {
-    (void)sysimage_base; (void)base; (void)offsets; (void)linfos; (void)n;
+    (void)sysimage_base; (void)fptrs; (void)linfos; (void)n;
 }
 
 void jl_compile_linfo(jl_method_instance_t *li) { }
diff --git a/src/debuginfo.cpp b/src/debuginfo.cpp
index 3c232af029..08d4f78386 100644
--- a/src/debuginfo.cpp
+++ b/src/debuginfo.cpp
@@ -37,6 +37,7 @@ using llvm_file_magic = sys::fs::file_magic;
 #if defined(_OS_LINUX_)
 #  include <link.h>
 #endif
+#include "processor.h"
 
 #include <string>
 #include <sstream>
@@ -706,20 +707,14 @@ openDebugInfo(StringRef debuginfopath, const debug_link_info &info)
 }
 
 static uint64_t jl_sysimage_base;
-static const char *sysimg_fvars_base = nullptr;
-static const int32_t *sysimg_fvars_offsets;
+static jl_sysimg_fptrs_t sysimg_fptrs;
 static jl_method_instance_t **sysimg_fvars_linfo;
 static size_t sysimg_fvars_n;
-static const void *sysimg_fvars(size_t idx)
-{
-    return sysimg_fvars_base + sysimg_fvars_offsets[idx];
-}
-void jl_register_fptrs(uint64_t sysimage_base, const char *base, const int32_t *offsets,
+void jl_register_fptrs(uint64_t sysimage_base, const jl_sysimg_fptrs_t *fptrs,
                        jl_method_instance_t **linfos, size_t n)
 {
     jl_sysimage_base = (uintptr_t)sysimage_base;
-    sysimg_fvars_base = base;
-    sysimg_fvars_offsets = offsets;
+    sysimg_fptrs = *fptrs;
     sysimg_fvars_linfo = linfos;
     sysimg_fvars_n = n;
 }
@@ -738,7 +733,7 @@ static void get_function_name_and_base(const object::ObjectFile *object, bool in
                                        int64_t slide, bool untrusted_dladdr)
 {
     // Assume we only need base address for sysimg for now
-    if (!insysimage || !sysimg_fvars_base)
+    if (!insysimage || !sysimg_fptrs.base)
         saddr = nullptr;
     bool needs_saddr = saddr && (!*saddr || untrusted_dladdr);
     bool needs_name = name && (!*name || untrusted_dladdr);
@@ -1089,9 +1084,17 @@ static int jl_getDylibFunctionInfo(jl_frame_t **frames, size_t pointer, int skip
         return 1;
     }
     frame0->fromC = !isSysImg;
-    if (isSysImg && sysimg_fvars_base && saddr) {
+    if (isSysImg && sysimg_fptrs.base && saddr) {
+        intptr_t diff = (uintptr_t)saddr - (uintptr_t)sysimg_fptrs.base;
+        for (size_t i = 0; i < sysimg_fptrs.nclones; i++) {
+            if (diff == sysimg_fptrs.clone_offsets[i]) {
+                uint32_t idx = sysimg_fptrs.clone_idxs[i] & jl_sysimg_val_mask;
+                frame0->linfo = sysimg_fvars_linfo[idx];
+                break;
+            }
+        }
         for (size_t i = 0; i < sysimg_fvars_n; i++) {
-            if (saddr == sysimg_fvars(i)) {
+            if (diff == sysimg_fptrs.offsets[i]) {
                 frame0->linfo = sysimg_fvars_linfo[i];
                 break;
             }
diff --git a/src/jitlayers.cpp b/src/jitlayers.cpp
index 754bc5db76..e88ee65d3e 100644
--- a/src/jitlayers.cpp
+++ b/src/jitlayers.cpp
@@ -97,7 +97,7 @@ void addTargetPasses(legacy::PassManagerBase *PM, TargetMachine *TM)
 
 // this defines the set of optimization passes defined for Julia at various optimization levels.
 // it assumes that the TLI and TTI wrapper passes have already been added.
-void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level)
+void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level, bool dump_native)
 {
 #ifdef JL_DEBUG_BUILD
     PM->add(createGCInvariantVerifierPass(true));
@@ -133,6 +133,8 @@ void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level)
         PM->add(createLateLowerGCFramePass());
         PM->add(createLowerPTLSPass(imaging_mode));
 #endif
+        if (dump_native)
+            PM->add(createMultiVersioningPass());
         return;
     }
     PM->add(createPropagateJuliaAddrspaces());
@@ -172,6 +174,8 @@ void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level)
     PM->add(createAllocOptPass());
 #endif
     PM->add(createInstructionCombiningPass()); // Cleanup for scalarrepl.
+    if (dump_native)
+        PM->add(createMultiVersioningPass());
     PM->add(createSROAPass());                 // Break up aggregate allocas
     PM->add(createInstructionCombiningPass()); // Cleanup for scalarrepl.
     PM->add(createJumpThreadingPass());        // Thread jumps.
@@ -1019,20 +1023,18 @@ void jl_add_to_shadow(Module *m)
 
 static void emit_offset_table(Module *mod, const std::vector<GlobalValue*> &vars, StringRef name)
 {
+    // Emit a global variable with all the variable addresses.
+    // The cloning pass will convert them into offsets.
     assert(!vars.empty());
-    addComdat(GlobalAlias::create(GlobalVariable::ExternalLinkage, name + "_base", vars[0]));
-    auto vbase = ConstantExpr::getPtrToInt(vars[0], T_size);
     size_t nvars = vars.size();
-    std::vector<Constant*> offsets(nvars);
-    for (size_t i = 0; i < nvars; i++) {
-        auto ptrdiff = ConstantExpr::getSub(ConstantExpr::getPtrToInt(vars[i], T_size), vbase);
-        offsets[i] = sizeof(void*) == 8 ? ConstantExpr::getTrunc(ptrdiff, T_uint32) : ptrdiff;
-    }
-    ArrayType *vars_type = ArrayType::get(T_uint32, nvars);
-    addComdat(new GlobalVariable(*mod, vars_type, true,
-                                 GlobalVariable::ExternalLinkage,
-                                 ConstantArray::get(vars_type, ArrayRef<Constant*>(offsets)),
-                                 name + "_offsets"));
+    std::vector<Constant*> addrs(nvars);
+    for (size_t i = 0; i < nvars; i++)
+        addrs[i] = ConstantExpr::getBitCast(vars[i], T_psize);
+    ArrayType *vars_type = ArrayType::get(T_psize, nvars);
+    new GlobalVariable(*mod, vars_type, true,
+                       GlobalVariable::ExternalLinkage,
+                       ConstantArray::get(vars_type, addrs),
+                       name);
 }
 
 
@@ -1141,7 +1143,7 @@ void jl_dump_native(const char *bc_fname, const char *unopt_bc_fname, const char
     }
 
     if (bc_fname || obj_fname)
-        addOptimizationPasses(&PM, jl_options.opt_level);
+        addOptimizationPasses(&PM, jl_options.opt_level, true);
 
     if (bc_fname) {
         // call output handler directly to avoid special case handling of `-` filename
diff --git a/src/jitlayers.h b/src/jitlayers.h
index 9b20c9d704..c7e48f10f1 100644
--- a/src/jitlayers.h
+++ b/src/jitlayers.h
@@ -43,7 +43,7 @@ extern size_t jltls_offset_idx;
 typedef struct {Value *gv; int32_t index;} jl_value_llvm; // uses 1-based indexing
 
 void addTargetPasses(legacy::PassManagerBase *PM, TargetMachine *TM);
-void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level);
+void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level, bool dump_native=false);
 void* jl_emit_and_add_to_shadow(GlobalVariable *gv, void *gvarinit = NULL);
 GlobalVariable *jl_emit_sysimg_slot(Module *m, Type *typ, const char *name,
                                     uintptr_t init, size_t &idx);
@@ -191,6 +191,7 @@ Pass *createLateLowerGCFramePass();
 Pass *createLowerExcHandlersPass();
 Pass *createGCInvariantVerifierPass(bool Strong);
 Pass *createPropagateJuliaAddrspaces();
+Pass *createMultiVersioningPass();
 Pass *createAllocOptPass();
 // Whether the Function is an llvm or julia intrinsic.
 static inline bool isIntrinsicFunction(Function *F)
diff --git a/src/julia_internal.h b/src/julia_internal.h
index 8d1a44c658..cd26085665 100644
--- a/src/julia_internal.h
+++ b/src/julia_internal.h
@@ -998,7 +998,9 @@ extern jl_sym_t *nospecialize_sym;
 extern jl_sym_t *boundscheck_sym;
 extern jl_sym_t *gc_preserve_begin_sym; extern jl_sym_t *gc_preserve_end_sym;
 
-void jl_register_fptrs(uint64_t sysimage_base, const char *base, const int32_t *offsets,
+struct _jl_sysimg_fptrs_t;
+
+void jl_register_fptrs(uint64_t sysimage_base, const struct _jl_sysimg_fptrs_t *fptrs,
                        jl_method_instance_t **linfos, size_t n);
 
 extern arraylist_t partial_inst;
diff --git a/src/llvm-multiversioning.cpp b/src/llvm-multiversioning.cpp
new file mode 100644
index 0000000000..22ef07f8d0
--- /dev/null
+++ b/src/llvm-multiversioning.cpp
@@ -0,0 +1,1067 @@
+// This file is a part of Julia. License is MIT: https://julialang.org/license
+
+// Function multi-versioning
+#define DEBUG_TYPE "julia_multiversioning"
+#undef DEBUG
+
+// LLVM pass to clone function for different archs
+
+#include "llvm-version.h"
+#include "support/dtypes.h"
+
+#include <llvm/Pass.h>
+#include <llvm/IR/Module.h>
+#include <llvm/IR/Function.h>
+#include <llvm/IR/Instructions.h>
+#include <llvm/IR/Constants.h>
+#include <llvm/IR/LLVMContext.h>
+#include <llvm/Analysis/LoopInfo.h>
+#include <llvm/Analysis/CallGraph.h>
+#include <llvm/IR/LegacyPassManager.h>
+#include <llvm/IR/MDBuilder.h>
+#include <llvm/IR/IRBuilder.h>
+#include <llvm/IR/DebugInfoMetadata.h>
+#include <llvm/Transforms/Utils/Cloning.h>
+
+#include "julia.h"
+#include "julia_internal.h"
+#include "processor.h"
+
+#include <map>
+#include <memory>
+#include <set>
+#include <vector>
+
+#include "codegen_shared.h"
+#include "julia_assert.h"
+
+using namespace llvm;
+
+extern std::pair<MDNode*,MDNode*> tbaa_make_child(const char *name, MDNode *parent=nullptr,
+                                                  bool isConstant=false);
+
+namespace {
+
+// These are valid detail cloning conditions in the target flags.
+constexpr uint32_t clone_mask =
+    JL_TARGET_CLONE_LOOP | JL_TARGET_CLONE_SIMD | JL_TARGET_CLONE_MATH;
+
+struct MultiVersioning;
+
+// Treat identical mapping as missing and return `def` in that case.
+// We mainly need this to identify cloned function using value map after LLVM cloning
+// functions fills the map with identity entries.
+template<typename T>
+Value *map_get(T &&vmap, Value *key, Value *def=nullptr)
+{
+    auto val = vmap.lookup(key);
+    if (!val || key == val)
+        return def;
+    return val;
+}
+
+// Iterate through uses of a particular type.
+// Recursively scan through `ConstantExpr` and `ConstantAggregate` use.
+template<typename U>
+struct ConstantUses {
+    template<typename T>
+    struct Info {
+        Use *use;
+        T *val;
+        // If `samebits == true`, the offset the original value appears in the constant.
+        size_t offset;
+        // This specify whether the original value appears in the current value in exactly
+        // the same bit pattern (with possibly an offset determined by `offset`).
+        bool samebits;
+        Info(Use *use, T *val, size_t offset, bool samebits) :
+            use(use),
+            val(val),
+            offset(offset),
+            samebits(samebits)
+        {
+        }
+        Info(Use *use, size_t offset, bool samebits) :
+            use(use),
+            val(cast<T>(use->getUser())),
+            offset(offset),
+            samebits(samebits)
+        {
+        }
+    };
+    using UseInfo = Info<U>;
+    struct Frame : Info<Constant> {
+        template<typename... Args>
+        Frame(Args &&... args) :
+            Info<Constant>(std::forward<Args>(args)...),
+            cur(this->val->use_empty() ? nullptr : &*this->val->use_begin()),
+            _next(cur ? cur->getNext() : nullptr)
+        {
+        }
+    private:
+        void next()
+        {
+            cur = _next;
+            if (!cur)
+                return;
+            _next = cur->getNext();
+        }
+        Use *cur;
+        Use *_next;
+        friend struct ConstantUses;
+    };
+    ConstantUses(Constant *c, Module &M)
+        : stack{Frame(nullptr, c, 0u, true)},
+          M(M)
+    {
+        forward();
+    }
+    UseInfo get_info() const
+    {
+        auto &top = stack.back();
+        return UseInfo(top.cur, top.offset, top.samebits);
+    }
+    const SmallVector<Frame, 4> &get_stack() const
+    {
+        return stack;
+    }
+    void next()
+    {
+        stack.back().next();
+        forward();
+    }
+    bool done()
+    {
+        return stack.empty();
+    }
+private:
+    void forward();
+    SmallVector<Frame, 4> stack;
+    Module &M;
+};
+
+template<typename U>
+void ConstantUses<U>::forward()
+{
+    assert(!stack.empty());
+    auto frame = &stack.back();
+    const DataLayout &DL = M.getDataLayout();
+    auto pop = [&] {
+        stack.pop_back();
+        if (stack.empty()) {
+            return false;
+        }
+        frame = &stack.back();
+        return true;
+    };
+    auto push = [&] (Use *use, Constant *c, size_t offset, bool samebits) {
+        stack.emplace_back(use, c, offset, samebits);
+        frame = &stack.back();
+    };
+    auto handle_constaggr = [&] (Use *use, ConstantAggregate *aggr) {
+        if (!frame->samebits) {
+            push(use, aggr, 0, false);
+            return;
+        }
+        if (auto strct = dyn_cast<ConstantStruct>(aggr)) {
+            auto layout = DL.getStructLayout(strct->getType());
+            push(use, strct, frame->offset + layout->getElementOffset(use->getOperandNo()), true);
+        }
+        else if (auto ary = dyn_cast<ConstantArray>(aggr)) {
+            auto elty = ary->getType()->getElementType();
+            push(use, ary, frame->offset + DL.getTypeAllocSize(elty) * use->getOperandNo(), true);
+        }
+        else if (auto vec = dyn_cast<ConstantVector>(aggr)) {
+            auto elty = vec->getType()->getElementType();
+            push(use, vec, frame->offset + DL.getTypeAllocSize(elty) * use->getOperandNo(), true);
+        }
+        else {
+            jl_safe_printf("Unknown ConstantAggregate:\n");
+            llvm_dump(aggr);
+            abort();
+        }
+    };
+    auto handle_constexpr = [&] (Use *use, ConstantExpr *expr) {
+        if (!frame->samebits) {
+            push(use, expr, 0, false);
+            return;
+        }
+        auto opcode = expr->getOpcode();
+        if (opcode == Instruction::PtrToInt || opcode == Instruction::IntToPtr ||
+            opcode == Instruction::AddrSpaceCast || opcode == Instruction::BitCast) {
+            push(use, expr, frame->offset, true);
+        }
+        else {
+            push(use, expr, 0, false);
+        }
+    };
+    while (true) {
+        auto use = frame->cur;
+        if (!use) {
+            if (!pop())
+                return;
+            continue;
+        }
+        auto user = use->getUser();
+        if (isa<U>(user))
+            return;
+        frame->next();
+        if (auto aggr = dyn_cast<ConstantAggregate>(user)) {
+            handle_constaggr(use, aggr);
+        }
+        else if (auto expr = dyn_cast<ConstantExpr>(user)) {
+            handle_constexpr(use, expr);
+        }
+    }
+}
+
+struct CloneCtx {
+    struct Target {
+        int idx;
+        uint32_t flags;
+        std::unique_ptr<ValueToValueMapTy> vmap; // ValueToValueMapTy is not movable....
+        // function ids that needs relocation to be initialized
+        std::set<uint32_t> relocs{};
+        Target(int idx, const jl_target_spec_t &spec) :
+            idx(idx),
+            flags(spec.flags),
+            vmap(new ValueToValueMapTy)
+        {
+        }
+    };
+    struct Group : Target {
+        std::vector<Target> clones;
+        std::set<uint32_t> clone_fs;
+        Group(int base, const jl_target_spec_t &spec) :
+            Target(base, spec),
+            clones{},
+            clone_fs{}
+        {}
+        Function *base_func(Function *orig_f) const
+        {
+            if (idx == 0)
+                return orig_f;
+            return cast<Function>(vmap->lookup(orig_f));
+        }
+    };
+    CloneCtx(MultiVersioning *pass, Module &M);
+    void clone_bases();
+    void collect_func_infos();
+    void clone_all_partials();
+    void fix_gv_uses();
+    void fix_inst_uses();
+    void emit_metadata();
+private:
+    void prepare_vmap(ValueToValueMapTy &vmap);
+    bool is_vector(FunctionType *ty) const;
+    void clone_function(Function *F, Function *new_f, ValueToValueMapTy &vmap);
+    uint32_t collect_func_info(Function &F);
+    void check_partial(Group &grp, Target &tgt);
+    void clone_partial(Group &grp, Target &tgt);
+    void add_features(Function *F, StringRef name, StringRef features) const;
+    template<typename T>
+    T *add_comdat(T *G) const;
+    uint32_t get_func_id(Function *F);
+    template<typename Stack>
+    Constant *rewrite_gv_init(const Stack& stack);
+    template<typename Stack>
+    Value *rewrite_inst_use(const Stack& stack, Value *replace, Instruction *insert_before);
+    std::pair<uint32_t,GlobalVariable*> get_reloc_slot(Function *F);
+    Constant *get_ptrdiff32(Constant *ptr, Constant *base) const;
+    template<typename T>
+    Constant *emit_offset_table(const std::vector<T*> &vars, StringRef name) const;
+
+    LLVMContext &ctx;
+    Type *T_size;
+    Type *T_int32;
+    Type *T_void;
+    PointerType *T_psize;
+    PointerType *T_pvoidfunc;
+    MDNode *tbaa_const;
+    MultiVersioning *pass;
+    std::vector<jl_target_spec_t> specs;
+    std::vector<Group> groups{};
+    std::vector<Function*> fvars;
+    std::vector<Constant*> gvars;
+    Module &M;
+    // Map from original functiton to one based index in `fvars`
+    std::map<const Function*,uint32_t> func_ids{};
+    std::vector<Function*> orig_funcs{};
+    std::vector<uint32_t> func_infos{};
+    std::set<Function*> cloned{};
+    // GV addresses and their corresponding function id (i.e. 0-based index in `fvars`)
+    std::vector<std::pair<Constant*,uint32_t>> gv_relocs{};
+    // Mapping from function id (i.e. 0-based index in `fvars`) to GVs to be initialized.
+    std::map<uint32_t,GlobalVariable*> const_relocs;
+    bool has_veccall{false};
+    bool has_cloneall{false};
+};
+
+struct MultiVersioning: public ModulePass {
+    static char ID;
+    MultiVersioning()
+        : ModulePass(ID)
+    {}
+
+private:
+    bool runOnModule(Module &M) override;
+    void getAnalysisUsage(AnalysisUsage &AU) const override
+    {
+        AU.addRequired<LoopInfoWrapperPass>();
+        AU.addRequired<CallGraphWrapperPass>();
+        AU.addPreserved<LoopInfoWrapperPass>();
+    }
+    friend struct CloneCtx;
+};
+
+template<typename T>
+static inline std::vector<T*> consume_gv(Module &M, const char *name)
+{
+    // Get information about sysimg export functions from the two global variables.
+    // Strip them from the Module so that it's easier to handle the uses.
+    GlobalVariable *gv = M.getGlobalVariable(name);
+    assert(gv && gv->hasInitializer());
+    auto *ary = cast<ConstantArray>(gv->getInitializer());
+    unsigned nele = ary->getNumOperands();
+    std::vector<T*> res(nele);
+    for (unsigned i = 0; i < nele; i++)
+        res[i] = cast<T>(ary->getOperand(i)->stripPointerCasts());
+    assert(gv->use_empty());
+    gv->eraseFromParent();
+    if (ary->use_empty())
+        ary->destroyConstant();
+    return res;
+}
+
+// Collect basic information about targets and functions.
+CloneCtx::CloneCtx(MultiVersioning *pass, Module &M)
+    : ctx(M.getContext()),
+      T_size(M.getDataLayout().getIntPtrType(ctx, 0)),
+      T_int32(Type::getInt32Ty(ctx)),
+      T_void(Type::getVoidTy(ctx)),
+      T_psize(PointerType::get(T_size, 0)),
+      T_pvoidfunc(FunctionType::get(T_void, false)->getPointerTo()),
+      tbaa_const(tbaa_make_child("jtbaa_const", nullptr, true).first),
+      pass(pass),
+      specs(jl_get_llvm_clone_targets()),
+      fvars(consume_gv<Function>(M, "jl_sysimg_fvars")),
+      gvars(consume_gv<Constant>(M, "jl_sysimg_gvars")),
+      M(M)
+{
+    groups.emplace_back(0, specs[0]);
+    uint32_t ntargets = specs.size();
+    for (uint32_t i = 1; i < ntargets; i++) {
+        auto &spec = specs[i];
+        if (spec.flags & JL_TARGET_CLONE_ALL) {
+            has_cloneall = true;
+            groups.emplace_back(i, spec);
+        }
+        else {
+            auto base = spec.base;
+            bool found = false;
+            for (auto &grp: groups) {
+                if (grp.idx == base) {
+                    found = true;
+                    grp.clones.emplace_back(i, spec);
+                    break;
+                }
+            }
+            (void)found;
+        }
+    }
+    uint32_t nfvars = fvars.size();
+    for (uint32_t i = 0; i < nfvars; i++)
+        func_ids[fvars[i]] = i + 1;
+    for (auto &F: M) {
+        if (F.empty())
+            continue;
+        orig_funcs.push_back(&F);
+    }
+}
+
+void CloneCtx::prepare_vmap(ValueToValueMapTy &vmap)
+{
+    // Workaround LLVM `CloneFunctionInfo` bug (?) pre-5.0
+    // The `DICompileUnit`s are being cloned but are not added to the `llvm.dbg.cu` metadata
+    // which triggers assertions when generating native code/in the verifier.
+    // Fix this by forcing an identical mapping for all `DICompileUnit` recorded.
+    // The `DISubprogram` cloning on LLVM 5.0 handles this
+    // but it doesn't hurt to enforce the identity either.
+    auto &MD = vmap.MD();
+    for (auto cu: M.debug_compile_units()) {
+        MD[cu].reset(cu);
+    }
+}
+
+void CloneCtx::clone_function(Function *F, Function *new_f, ValueToValueMapTy &vmap)
+{
+    Function::arg_iterator DestI = new_f->arg_begin();
+    for (Function::const_arg_iterator J = F->arg_begin(); J != F->arg_end(); ++J) {
+        DestI->setName(J->getName());
+        vmap[&*J] = &*DestI++;
+    }
+    SmallVector<ReturnInst*,8> Returns;
+    CloneFunctionInto(new_f, F, vmap, true, Returns);
+}
+
+// Clone all clone_all targets. Makes sure that the base targets are all available.
+void CloneCtx::clone_bases()
+{
+    if (!has_cloneall)
+        return;
+    uint32_t ngrps = groups.size();
+    for (uint32_t gid = 1; gid < ngrps; gid++) {
+        auto &grp = groups[gid];
+        auto suffix = ".clone_" + std::to_string(grp.idx);
+        auto &vmap = *grp.vmap;
+        // Fill in old->new mapping. We need to do this before cloning the function so that
+        // the intra target calls are automatically fixed up on cloning.
+        for (auto F: orig_funcs) {
+            Function *new_f = Function::Create(F->getFunctionType(), F->getLinkage(),
+                                               F->getName() + suffix, &M);
+            new_f->copyAttributesFrom(F);
+            vmap[F] = new_f;
+        }
+        prepare_vmap(vmap);
+        for (auto F: orig_funcs) {
+            clone_function(F, cast<Function>(vmap.lookup(F)), vmap);
+        }
+    }
+}
+
+bool CloneCtx::is_vector(FunctionType *ty) const
+{
+    if (ty->getReturnType()->isVectorTy())
+        return true;
+    for (auto arg: ty->params()) {
+        if (arg->isVectorTy()) {
+            return true;
+        }
+    }
+    return false;
+}
+
+uint32_t CloneCtx::collect_func_info(Function &F)
+{
+    uint32_t flag = 0;
+    if (!pass->getAnalysis<LoopInfoWrapperPass>(F).getLoopInfo().empty())
+        flag |= JL_TARGET_CLONE_LOOP;
+    if (is_vector(F.getFunctionType())) {
+        flag |= JL_TARGET_CLONE_SIMD;
+        has_veccall = true;
+    }
+    for (auto &bb: F) {
+        for (auto &I: bb) {
+            if (auto call = dyn_cast<CallInst>(&I)) {
+                if (is_vector(call->getFunctionType())) {
+                    has_veccall = true;
+                    flag |= JL_TARGET_CLONE_SIMD;
+                }
+                if (auto callee = call->getCalledFunction()) {
+                    auto name = callee->getName();
+                    if (name.startswith("llvm.muladd.") || name.startswith("llvm.fma.")) {
+                        flag |= JL_TARGET_CLONE_MATH;
+                    }
+                }
+            }
+            else if (auto store = dyn_cast<StoreInst>(&I)) {
+                if (store->getValueOperand()->getType()->isVectorTy()) {
+                    flag |= JL_TARGET_CLONE_SIMD;
+                }
+            }
+            else if (I.getType()->isVectorTy()) {
+                flag |= JL_TARGET_CLONE_SIMD;
+            }
+            if (auto mathOp = dyn_cast<FPMathOperator>(&I)) {
+                if (mathOp->getFastMathFlags().any()) {
+                    flag |= JL_TARGET_CLONE_MATH;
+                }
+            }
+            if (has_veccall && (flag & JL_TARGET_CLONE_SIMD) && (flag & JL_TARGET_CLONE_MATH)) {
+                return flag;
+            }
+        }
+    }
+    return flag;
+}
+
+void CloneCtx::collect_func_infos()
+{
+    uint32_t nfuncs = orig_funcs.size();
+    func_infos.resize(nfuncs);
+    for (uint32_t i = 0; i < nfuncs; i++) {
+        func_infos[i] = collect_func_info(*orig_funcs[i]);
+    }
+}
+
+void CloneCtx::clone_all_partials()
+{
+    // First decide what to clone
+    // Do this before actually cloning the functions
+    // so that the call graph is easier to understand
+    for (auto &grp: groups) {
+        for (auto &tgt: grp.clones) {
+            check_partial(grp, tgt);
+        }
+    }
+    for (auto &grp: groups) {
+        for (auto &tgt: grp.clones)
+            clone_partial(grp, tgt);
+        // Also set feature strings for base target functions
+        // now that all the actual cloning is done.
+        auto &base_spec = specs[grp.idx];
+        for (auto orig_f: orig_funcs) {
+            add_features(grp.base_func(orig_f), base_spec.cpu_name, base_spec.cpu_features);
+        }
+    }
+    func_infos.clear(); // We don't need this anymore
+}
+
+void CloneCtx::check_partial(Group &grp, Target &tgt)
+{
+    auto flag = specs[tgt.idx].flags & clone_mask;
+    auto suffix = ".clone_" + std::to_string(tgt.idx);
+    auto &vmap = *tgt.vmap;
+    uint32_t nfuncs = func_infos.size();
+
+    std::set<Function*> all_origs;
+    // Use a simple heuristic to decide which function we need to clone.
+    for (uint32_t i = 0; i < nfuncs; i++) {
+        if (!(func_infos[i] & flag))
+            continue;
+        auto orig_f = orig_funcs[i];
+        // Fill in old->new mapping. We need to do this before cloning the function so that
+        // the intra target calls are automatically fixed up on cloning.
+        auto F = grp.base_func(orig_f);
+        Function *new_f = Function::Create(F->getFunctionType(), F->getLinkage(),
+                                           F->getName() + suffix, &M);
+        new_f->copyAttributesFrom(F);
+        vmap[F] = new_f;
+        if (!has_cloneall)
+            cloned.insert(orig_f);
+        grp.clone_fs.insert(i);
+        all_origs.insert(orig_f);
+    }
+    std::set<Function*> sets[2] = {all_origs, {}};
+    auto *cur_set = &sets[0];
+    auto *next_set = &sets[1];
+    // Reduce dispatch by expand the cloning set to functions that are directly called by
+    // and calling cloned functions.
+    auto &graph = pass->getAnalysis<CallGraphWrapperPass>().getCallGraph();
+    while (!cur_set->empty()) {
+        for (auto orig_f: *cur_set) {
+            // Use the uncloned function since it's already in the call graph
+            auto node = graph[orig_f];
+            for (const auto &I: *node) {
+                auto child_node = I.second;
+                auto orig_child_f = child_node->getFunction();
+                if (!orig_child_f)
+                    continue;
+                // Already cloned
+                if (all_origs.count(orig_child_f))
+                    continue;
+                bool calling_clone = false;
+                for (const auto &I2: *child_node) {
+                    auto orig_child_f2 = I2.second->getFunction();
+                    if (!orig_child_f2)
+                        continue;
+                    if (all_origs.count(orig_child_f2)) {
+                        calling_clone = true;
+                        break;
+                    }
+                }
+                if (!calling_clone)
+                    continue;
+                next_set->insert(orig_child_f);
+                all_origs.insert(orig_child_f);
+                auto child_f = grp.base_func(orig_child_f);
+                Function *new_f = Function::Create(child_f->getFunctionType(),
+                                                   child_f->getLinkage(),
+                                                   child_f->getName() + suffix, &M);
+                new_f->copyAttributesFrom(child_f);
+                vmap[child_f] = new_f;
+            }
+        }
+        std::swap(cur_set, next_set);
+        next_set->clear();
+    }
+    for (uint32_t i = 0; i < nfuncs; i++) {
+        // Only need to handle expanded functions
+        if (func_infos[i] & flag)
+            continue;
+        auto orig_f = orig_funcs[i];
+        if (all_origs.count(orig_f)) {
+            if (!has_cloneall)
+                cloned.insert(orig_f);
+            grp.clone_fs.insert(i);
+        }
+    }
+}
+
+void CloneCtx::clone_partial(Group &grp, Target &tgt)
+{
+    auto &spec = specs[tgt.idx];
+    auto &vmap = *tgt.vmap;
+    uint32_t nfuncs = orig_funcs.size();
+    prepare_vmap(vmap);
+    for (uint32_t i = 0; i < nfuncs; i++) {
+        auto orig_f = orig_funcs[i];
+        auto F = grp.base_func(orig_f);
+        if (auto new_v = map_get(vmap, F)) {
+            auto new_f = cast<Function>(new_v);
+            assert(new_f != F);
+            clone_function(F, new_f, vmap);
+            // We can set the feature strings now since no one is going to
+            // clone these functions again.
+            add_features(new_f, spec.cpu_name, spec.cpu_features);
+        }
+    }
+}
+
+void CloneCtx::add_features(Function *F, StringRef name, StringRef features) const
+{
+    auto attr = F->getFnAttribute("target-features");
+    if (attr.isStringAttribute()) {
+        std::string new_features = attr.getValueAsString();
+        new_features += ",";
+        new_features += features;
+        F->addFnAttr("target-features", new_features);
+    }
+    else {
+        F->addFnAttr("target-features", features);
+    }
+    F->addFnAttr("target-cpu", name);
+}
+
+uint32_t CloneCtx::get_func_id(Function *F)
+{
+    auto &ref = func_ids[F];
+    if (!ref) {
+        fvars.push_back(F);
+        ref = fvars.size();
+    }
+    return ref - 1;
+}
+
+template<typename Stack>
+Constant *CloneCtx::rewrite_gv_init(const Stack& stack)
+{
+    // Null initialize so that LLVM put it in the correct section.
+    SmallVector<Constant*, 8> args;
+    Constant *res = ConstantPointerNull::get(cast<PointerType>(stack[0].val->getType()));
+    uint32_t nlevel = stack.size();
+    for (uint32_t i = 1; i < nlevel; i++) {
+        auto &frame = stack[i];
+        auto val = frame.val;
+        Use *use = frame.use;
+        unsigned idx = use->getOperandNo();
+        unsigned nargs = val->getNumOperands();
+        args.resize(nargs);
+        for (unsigned j = 0; j < nargs; j++) {
+            if (idx == j) {
+                args[j] = res;
+            }
+            else {
+                args[j] = cast<Constant>(val->getOperand(j));
+            }
+        }
+        if (auto expr = dyn_cast<ConstantExpr>(val)) {
+            res = expr->getWithOperands(args);
+        }
+        else if (auto ary = dyn_cast<ConstantArray>(val)) {
+            res = ConstantArray::get(ary->getType(), args);
+        }
+        else if (auto strct = dyn_cast<ConstantStruct>(val)) {
+            res = ConstantStruct::get(strct->getType(), args);
+        }
+        else if (isa<ConstantVector>(val)) {
+            res = ConstantVector::get(args);
+        }
+        else {
+            jl_safe_printf("Unknown const use.");
+            llvm_dump(val);
+            abort();
+        }
+    }
+    return res;
+}
+
+void CloneCtx::fix_gv_uses()
+{
+    auto single_pass = [&] (Function *orig_f) {
+        bool changed = false;
+        for (auto uses = ConstantUses<GlobalValue>(orig_f, M); !uses.done(); uses.next()) {
+            changed = true;
+            auto &stack = uses.get_stack();
+            auto info = uses.get_info();
+            // We only support absolute pointer relocation.
+            assert(info.samebits);
+            // And only for non-constant global variable initializers
+            auto val = cast<GlobalVariable>(info.val);
+            assert(info.use->getOperandNo() == 0);
+            assert(!val->isConstant());
+            auto fid = get_func_id(orig_f);
+            auto addr = ConstantExpr::getPtrToInt(val, T_size);
+            if (info.offset)
+                addr = ConstantExpr::getAdd(addr, ConstantInt::get(T_size, info.offset));
+            gv_relocs.emplace_back(addr, fid);
+            val->setInitializer(rewrite_gv_init(stack));
+        }
+        return changed;
+    };
+    for (auto orig_f: orig_funcs) {
+        if (!has_cloneall && !cloned.count(orig_f))
+            continue;
+        while (single_pass(orig_f)) {
+        }
+    }
+}
+
+std::pair<uint32_t,GlobalVariable*> CloneCtx::get_reloc_slot(Function *F)
+{
+    // Null initialize so that LLVM put it in the correct section.
+    auto id = get_func_id(F);
+    auto &slot = const_relocs[id];
+    if (!slot)
+        slot = new GlobalVariable(M, T_pvoidfunc, false, GlobalVariable::InternalLinkage,
+                                  ConstantPointerNull::get(T_pvoidfunc),
+                                  F->getName() + ".reloc_slot");
+    return std::make_pair(id, slot);
+}
+
+template<typename Stack>
+Value *CloneCtx::rewrite_inst_use(const Stack& stack, Value *replace, Instruction *insert_before)
+{
+    SmallVector<Constant*, 8> args;
+    uint32_t nlevel = stack.size();
+    for (uint32_t i = 1; i < nlevel; i++) {
+        auto &frame = stack[i];
+        auto val = frame.val;
+        Use *use = frame.use;
+        unsigned idx = use->getOperandNo();
+        if (auto expr = dyn_cast<ConstantExpr>(val)) {
+            auto inst = expr->getAsInstruction();
+            inst->replaceUsesOfWith(val->getOperand(idx), replace);
+            inst->insertBefore(insert_before);
+            replace = inst;
+            continue;
+        }
+        unsigned nargs = val->getNumOperands();
+        args.resize(nargs);
+        for (unsigned j = 0; j < nargs; j++) {
+            auto op = val->getOperand(j);
+            if (idx == j) {
+                args[j] = UndefValue::get(op->getType());
+            }
+            else {
+                args[j] = cast<Constant>(op);
+            }
+        }
+        if (auto ary = dyn_cast<ConstantArray>(val)) {
+            replace = InsertValueInst::Create(ConstantArray::get(ary->getType(), args),
+                                              replace, {idx}, "", insert_before);
+        }
+        else if (auto strct = dyn_cast<ConstantStruct>(val)) {
+            replace = InsertValueInst::Create(ConstantStruct::get(strct->getType(), args),
+                                              replace, {idx}, "", insert_before);
+        }
+        else if (isa<ConstantVector>(val)) {
+            replace = InsertElementInst::Create(ConstantVector::get(args), replace,
+                                                ConstantInt::get(T_size, idx), "",
+                                                insert_before);
+        }
+        else {
+            jl_safe_printf("Unknown const use.");
+            llvm_dump(val);
+            abort();
+        }
+    }
+    return replace;
+}
+
+void CloneCtx::fix_inst_uses()
+{
+    uint32_t nfuncs = orig_funcs.size();
+    for (auto &grp: groups) {
+        auto suffix = ".clone_" + std::to_string(grp.idx);
+        for (uint32_t i = 0; i < nfuncs; i++) {
+            if (!grp.clone_fs.count(i))
+                continue;
+            auto orig_f = orig_funcs[i];
+            auto F = grp.base_func(orig_f);
+            bool changed;
+            do {
+                changed = false;
+                for (auto uses = ConstantUses<Instruction>(F, M); !uses.done(); uses.next()) {
+                    auto info = uses.get_info();
+                    auto use_i = info.val;
+                    auto use_f = use_i->getFunction();
+                    if (!use_f->getName().endswith(suffix))
+                        continue;
+                    Instruction *insert_before = use_i;
+                    if (auto phi = dyn_cast<PHINode>(use_i))
+                        insert_before = phi->getIncomingBlock(*info.use)->getTerminator();
+                    uint32_t id;
+                    GlobalVariable *slot;
+                    std::tie(id, slot) = get_reloc_slot(orig_f);
+                    Instruction *ptr = new LoadInst(T_pvoidfunc, slot, "", false, insert_before);
+                    ptr->setMetadata(llvm::LLVMContext::MD_tbaa, tbaa_const);
+                    ptr = new BitCastInst(ptr, F->getType(), "", insert_before);
+                    use_i->setOperand(info.use->getOperandNo(),
+                                      rewrite_inst_use(uses.get_stack(), ptr,
+                                                       insert_before));
+
+                    grp.relocs.insert(id);
+                    for (auto &tgt: grp.clones) {
+                        // The enclosing function of the use is cloned,
+                        // no need to deal with this use on this target.
+                        if (map_get(*tgt.vmap, use_f))
+                            continue;
+                        tgt.relocs.insert(id);
+                    }
+
+                    changed = true;
+                }
+            } while (changed);
+        }
+    }
+}
+
+template<typename T>
+inline T *CloneCtx::add_comdat(T *G) const
+{
+#if defined(_OS_WINDOWS_)
+    // Add comdat information to make MSVC link.exe happy
+    // it's valid to emit this for ld.exe too,
+    // but makes it very slow to link for no benefit
+#if defined(_COMPILER_MICROSOFT_)
+    Comdat *jl_Comdat = G->getParent()->getOrInsertComdat(G->getName());
+    // ELF only supports Comdat::Any
+    jl_Comdat->setSelectionKind(Comdat::NoDuplicates);
+    G->setComdat(jl_Comdat);
+#endif
+    // add __declspec(dllexport) to everything marked for export
+    if (G->getLinkage() == GlobalValue::ExternalLinkage)
+        G->setDLLStorageClass(GlobalValue::DLLExportStorageClass);
+    else
+        G->setDLLStorageClass(GlobalValue::DefaultStorageClass);
+#endif
+    return G;
+}
+
+Constant *CloneCtx::get_ptrdiff32(Constant *ptr, Constant *base) const
+{
+    if (ptr->getType()->isPointerTy())
+        ptr = ConstantExpr::getPtrToInt(ptr, T_size);
+    auto ptrdiff = ConstantExpr::getSub(ptr, base);
+    return sizeof(void*) == 8 ? ConstantExpr::getTrunc(ptrdiff, T_int32) : ptrdiff;
+}
+
+template<typename T>
+Constant *CloneCtx::emit_offset_table(const std::vector<T*> &vars, StringRef name) const
+{
+    assert(!vars.empty());
+    add_comdat(GlobalAlias::create(T_size, 0, GlobalVariable::ExternalLinkage,
+                                   name + "_base",
+                                   ConstantExpr::getBitCast(vars[0], T_psize), &M));
+    auto vbase = ConstantExpr::getPtrToInt(vars[0], T_size);
+    uint32_t nvars = vars.size();
+    std::vector<Constant*> offsets(nvars + 1);
+    offsets[0] = ConstantInt::get(T_int32, nvars);
+    offsets[1] = ConstantInt::get(T_int32, 0);
+    for (uint32_t i = 1; i < nvars; i++)
+        offsets[i + 1] = get_ptrdiff32(vars[i], vbase);
+    ArrayType *vars_type = ArrayType::get(T_int32, nvars + 1);
+    add_comdat(new GlobalVariable(M, vars_type, true,
+                                  GlobalVariable::ExternalLinkage,
+                                  ConstantArray::get(vars_type, offsets),
+                                  name + "_offsets"));
+    return vbase;
+}
+
+void CloneCtx::emit_metadata()
+{
+    // Store back the information about exported functions.
+    auto fbase = emit_offset_table(fvars, "jl_sysimg_fvars");
+    auto gbase = emit_offset_table(gvars, "jl_sysimg_gvars");
+    uint32_t nfvars = fvars.size();
+
+    uint32_t ntargets = specs.size();
+    SmallVector<Target*, 8> targets(ntargets);
+    for (auto &grp: groups) {
+        targets[grp.idx] = &grp;
+        for (auto &tgt: grp.clones) {
+            targets[tgt.idx] = &tgt;
+        }
+    }
+
+    // Generate `jl_dispatch_target_ids`
+    {
+        const uint32_t base_flags = has_veccall ? JL_TARGET_VEC_CALL : 0;
+        std::vector<uint8_t> data;
+        auto push_i32 = [&] (uint32_t v) {
+            uint8_t buff[4];
+            memcpy(buff, &v, 4);
+            data.insert(data.end(), buff, buff + 4);
+        };
+        push_i32(ntargets);
+        for (uint32_t i = 0; i < ntargets; i++) {
+            push_i32(base_flags | (specs[i].flags & JL_TARGET_UNKNOWN_NAME));
+            auto &specdata = specs[i].data;
+            data.insert(data.end(), specdata.begin(), specdata.end());
+        }
+        auto value = ConstantDataArray::get(ctx, data);
+        add_comdat(new GlobalVariable(M, value->getType(), true,
+                                      GlobalVariable::ExternalLinkage,
+                                      value, "jl_dispatch_target_ids"));
+    }
+
+    // Generate `jl_dispatch_reloc_slots`
+    std::set<uint32_t> shared_relocs;
+    {
+        std::stable_sort(gv_relocs.begin(), gv_relocs.end(),
+                         [] (const std::pair<Constant*,uint32_t> &lhs,
+                             const std::pair<Constant*,uint32_t> &rhs) {
+                             return lhs.second < rhs.second;
+                         });
+        std::vector<Constant*> values{nullptr};
+        uint32_t gv_reloc_idx = 0;
+        uint32_t ngv_relocs = gv_relocs.size();
+        for (uint32_t id = 0; id < nfvars; id++) {
+            // TODO:
+            // explicitly set section? so that we are sure the relocation slots
+            // are in the same section as `gbase`.
+            auto id_v = ConstantInt::get(T_int32, id);
+            for (; gv_reloc_idx < ngv_relocs && gv_relocs[gv_reloc_idx].second == id;
+                 gv_reloc_idx++) {
+                shared_relocs.insert(id);
+                values.push_back(id_v);
+                values.push_back(get_ptrdiff32(gv_relocs[gv_reloc_idx].first, gbase));
+            }
+            auto it = const_relocs.find(id);
+            if (it != const_relocs.end()) {
+                values.push_back(id_v);
+                values.push_back(get_ptrdiff32(it->second, gbase));
+            }
+        }
+        values[0] = ConstantInt::get(T_int32, values.size() / 2);
+        ArrayType *vars_type = ArrayType::get(T_int32, values.size());
+        add_comdat(new GlobalVariable(M, vars_type, true, GlobalVariable::ExternalLinkage,
+                                      ConstantArray::get(vars_type, values),
+                                      "jl_dispatch_reloc_slots"));
+    }
+
+    // Generate `jl_dispatch_fvars_idxs` and `jl_dispatch_fvars_offsets`
+    {
+        std::vector<uint32_t> idxs;
+        std::vector<Constant*> offsets;
+        for (uint32_t i = 0; i < ntargets; i++) {
+            auto tgt = targets[i];
+            auto &spec = specs[i];
+            uint32_t len_idx = idxs.size();
+            idxs.push_back(0); // We will fill in the real value later.
+            uint32_t count = 0;
+            if (i == 0 || spec.flags & JL_TARGET_CLONE_ALL) {
+                auto grp = static_cast<Group*>(tgt);
+                count = jl_sysimg_tag_mask;
+                for (uint32_t j = 0; j < nfvars; j++) {
+                    if (shared_relocs.count(j) || tgt->relocs.count(j)) {
+                        count++;
+                        idxs.push_back(j);
+                    }
+                    if (i != 0) {
+                        offsets.push_back(get_ptrdiff32(grp->base_func(fvars[j]), fbase));
+                    }
+                }
+            }
+            else {
+                auto baseidx = spec.base;
+                auto grp = static_cast<Group*>(targets[baseidx]);
+                idxs.push_back(baseidx);
+                for (uint32_t j = 0; j < nfvars; j++) {
+                    auto base_f = grp->base_func(fvars[j]);
+                    if (shared_relocs.count(j)) {
+                        count++;
+                        idxs.push_back(jl_sysimg_tag_mask | j);
+                        auto f = map_get(*tgt->vmap, base_f, base_f);
+                        offsets.push_back(get_ptrdiff32(cast<Function>(f), fbase));
+                    }
+                    else if (auto f = map_get(*tgt->vmap, base_f)) {
+                        count++;
+                        idxs.push_back(tgt->relocs.count(j) ? (jl_sysimg_tag_mask | j) : j);
+                        offsets.push_back(get_ptrdiff32(cast<Function>(f), fbase));
+                    }
+                }
+            }
+            idxs[len_idx] = count;
+        }
+        auto idxval = ConstantDataArray::get(ctx, idxs);
+        add_comdat(new GlobalVariable(M, idxval->getType(), true,
+                                      GlobalVariable::ExternalLinkage,
+                                      idxval, "jl_dispatch_fvars_idxs"));
+        ArrayType *offsets_type = ArrayType::get(T_int32, offsets.size());
+        add_comdat(new GlobalVariable(M, offsets_type, true,
+                                      GlobalVariable::ExternalLinkage,
+                                      ConstantArray::get(offsets_type, offsets),
+                                      "jl_dispatch_fvars_offsets"));
+    }
+}
+
+bool MultiVersioning::runOnModule(Module &M)
+{
+    // Group targets and identify cloning bases.
+    // Also initialize function info maps (we'll update these maps as we go)
+    // Maps that we need includes,
+    //
+    //     * Original function -> ID (initialize from `fvars` and allocate ID lazily)
+    //     * Cloned function -> Original function (add as we clone functions)
+    //     * Original function -> Base function (target specific and updated by LLVM)
+    //     * ID -> relocation slots (const).
+    CloneCtx clone(this, M);
+
+    // Collect a list of original functions and clone base functions
+    clone.clone_bases();
+
+    // Collect function info (type of instruction used)
+    clone.collect_func_infos();
+
+    // If any partially cloned target exist decide which functions to clone for these targets.
+    // Clone functions for each group and collect a list of them.
+    // We can also add feature strings for cloned functions
+    // now that no additional cloning needs to be done.
+    clone.clone_all_partials();
+
+    // Scan **ALL** cloned functions (including full cloning for base target)
+    // for global variables initialization use.
+    // Replace them with `null` slot to be initialized at runtime and record relocation slot.
+    // These relocations must be initialized for **ALL** targets.
+    clone.fix_gv_uses();
+
+    // For each group, scan all functions cloned by **PARTIALLY** cloned targets for
+    // instruction use.
+    // A function needs a const relocation slot if it is cloned and is called by a
+    // uncloned function for at least one partially cloned target in the group.
+    // This is also the condition that a use in an uncloned function needs to be replaced with
+    // a slot load (i.e. if both the caller and the callee are always cloned or not cloned
+    // on all targets, the caller site does not need a relocation slot).
+    // A target needs a slot to be initialized iff at least one caller is not initialized.
+    clone.fix_inst_uses();
+
+    // Store back sysimg information with the correct format.
+    // At this point, we should have fixed up all the uses of the cloned functions
+    // and collected all the shared/target-specific relocations.
+    clone.emit_metadata();
+
+    return true;
+}
+
+char MultiVersioning::ID = 0;
+static RegisterPass<MultiVersioning> X("JuliaMultiVersioning", "JuliaMultiVersioning Pass",
+                                       false /* Only looks at CFG */,
+                                       false /* Analysis Pass */);
+
+}
+
+Pass *createMultiVersioningPass()
+{
+    return new MultiVersioning();
+}
diff --git a/src/processor.h b/src/processor.h
index 512b8a2936..8ab8fecbb2 100644
--- a/src/processor.h
+++ b/src/processor.h
@@ -124,7 +124,7 @@ int jl_test_cpu_feature(jl_cpu_feature_t feature);
 static const uint32_t jl_sysimg_tag_mask = 0x80000000u;
 static const uint32_t jl_sysimg_val_mask = ~((uint32_t)0x80000000u);
 
-typedef struct {
+typedef struct _jl_sysimg_fptrs_t {
     // base function pointer
     const char *base;
     // number of functions
diff --git a/src/staticdata.c b/src/staticdata.c
index 72986e5312..e06907947f 100644
--- a/src/staticdata.c
+++ b/src/staticdata.c
@@ -9,6 +9,7 @@
 #include "julia.h"
 #include "julia_internal.h"
 #include "builtin_proto.h"
+#include "processor.h"
 
 #ifndef _OS_WINDOWS_
 #include <dlfcn.h>
@@ -134,19 +135,13 @@ static void *jl_sysimg_handle = NULL;
 static uint64_t sysimage_base = 0;
 static uintptr_t *sysimg_gvars_base = NULL;
 static const int32_t *sysimg_gvars_offsets = NULL;
-static const char *sysimg_fvars_base = NULL;
-static const int32_t *sysimg_fvars_offsets = NULL;
+static jl_sysimg_fptrs_t sysimg_fptrs;
 
 static inline uintptr_t *sysimg_gvars(uintptr_t *base, size_t idx)
 {
     return base + sysimg_gvars_offsets[idx] / sizeof(base[0]);
 }
 
-static inline uintptr_t sysimg_fvars(const char *base, size_t idx)
-{
-    return (uintptr_t)(base + sysimg_fvars_offsets[idx]);
-}
-
 JL_DLLEXPORT int jl_running_on_valgrind(void)
 {
     return RUNNING_ON_VALGRIND;
@@ -160,9 +155,8 @@ static void jl_load_sysimg_so(void)
         sysimg_gvars_base = (uintptr_t*)jl_dlsym(jl_sysimg_handle, "jl_sysimg_gvars_base");
         sysimg_gvars_offsets = (const int32_t*)jl_dlsym(jl_sysimg_handle,
                                                         "jl_sysimg_gvars_offsets");
-        sysimg_fvars_base = (const char*)jl_dlsym(jl_sysimg_handle, "jl_sysimg_fvars_base");
-        sysimg_fvars_offsets = (const int32_t*)jl_dlsym(jl_sysimg_handle,
-                                                        "jl_sysimg_fvars_offsets");
+        sysimg_gvars_offsets += 1;
+        assert(sysimg_fptrs.base);
         globalUnique = *(size_t*)jl_dlsym(jl_sysimg_handle, "jl_globalUnique");
 #ifdef JULIA_ENABLE_THREADING
         size_t tls_getter_idx = *(size_t*)jl_dlsym(jl_sysimg_handle,
@@ -187,6 +181,9 @@ static void jl_load_sysimg_so(void)
         }
 #endif
     }
+    else {
+        memset(&sysimg_fptrs, 0, sizeof(sysimg_fptrs));
+    }
     const char *sysimg_data = (const char*)jl_dlsym(jl_sysimg_handle, "jl_system_image_data");
     size_t len = *(size_t*)jl_dlsym(jl_sysimg_handle, "jl_system_image_size");
     jl_restore_system_image_data(sysimg_data, len);
@@ -931,14 +928,15 @@ static jl_value_t *jl_read_value(jl_serializer_state *s)
 
 static void jl_update_all_fptrs(jl_serializer_state *s)
 {
-    const char *fvars_base = sysimg_fvars_base;
+    jl_sysimg_fptrs_t fvars = sysimg_fptrs;
     // make these NULL now so we skip trying to restore GlobalVariable pointers later
     sysimg_gvars_base = NULL;
-    sysimg_fvars_base = NULL;
+    sysimg_fptrs.base = NULL;
     int sysimg_fvars_max = s->fptr_record->size / sizeof(void*);
     size_t i;
     uintptr_t base = (uintptr_t)&s->s->buf[0];
     jl_method_instance_t **linfos = (jl_method_instance_t**)&s->fptr_record->buf[0];
+    uint32_t clone_idx = 0;
     for (i = 0; i < sysimg_fvars_max; i++) {
         uintptr_t val = (uintptr_t)&linfos[i];
         uint32_t offset = load_uint32_be(&val);
@@ -950,18 +948,28 @@ static void jl_update_all_fptrs(jl_serializer_state *s)
                 offset = ~offset;
             }
             jl_method_instance_t *li = (jl_method_instance_t*)(base + offset);
-            if (fvars_base == NULL) {
+            if (fvars.base == NULL) {
                 li->jlcall_api = 0;
             }
             else {
+                uintptr_t base = (uintptr_t)fvars.base;
                 assert(jl_is_method(li->def.method) && li->jlcall_api && li->jlcall_api != 2);
                 linfos[i] = li;
-                jl_fptr_to_llvm((jl_fptr_t)sysimg_fvars(fvars_base, i), li, cfunc);
+                int32_t offset = fvars.offsets[i];
+                for (; clone_idx < fvars.nclones; clone_idx++) {
+                    uint32_t idx = fvars.clone_idxs[clone_idx] & jl_sysimg_val_mask;
+                    if (idx < i)
+                        continue;
+                    if (idx == i)
+                        offset = fvars.clone_offsets[clone_idx];
+                    break;
+                }
+                jl_fptr_to_llvm((jl_fptr_t)(base + offset), li, cfunc);
             }
         }
     }
-    if (fvars_base) {
-        jl_register_fptrs(sysimage_base, fvars_base, sysimg_fvars_offsets, linfos, sysimg_fvars_max);
+    if (fvars.base) {
+        jl_register_fptrs(sysimage_base, &fvars, linfos, sysimg_fvars_max);
     }
 }
 
@@ -1339,6 +1347,7 @@ JL_DLLEXPORT void jl_set_sysimg_so(void *handle)
     if (jl_options.cpu_target == NULL)
         jl_options.cpu_target = "native";
     jl_sysimg_handle = handle;
+    sysimg_fptrs = jl_init_processor_sysimg(handle);
 }
 
 static void jl_restore_system_image_from_stream(ios_t *f)
-- 
2.14.2

