From 4e8d327ec9242d4e58cd685b404f2bffcbf3b005 Mon Sep 17 00:00:00 2001
From: Yichao Yu <yyc1992@gmail.com>
Date: Tue, 4 Jul 2017 22:14:59 -0400
Subject: [PATCH 6/8] Add LLVM level allocation optimization pass

This can obtain escape information with much higher precision than what we can currently do
in typeinf. However, it does not replace the alloc_elim_pass! in type inference either since
this cannot handle objects with reference fields.
---
 src/Makefile           |   2 +-
 src/ccall.cpp          |   2 +-
 src/cgutils.cpp        |  21 +-
 src/codegen.cpp        |  34 +--
 src/intrinsics.cpp     |   6 +-
 src/jitlayers.cpp      |   8 +
 src/jitlayers.h        |   1 +
 src/llvm-alloc-opt.cpp | 688 +++++++++++++++++++++++++++++++++++++++++++++++++
 test/codegen.jl        |  15 ++
 9 files changed, 732 insertions(+), 45 deletions(-)
 create mode 100644 src/llvm-alloc-opt.cpp

diff --git a/src/Makefile b/src/Makefile
index 9e2bf245d8..fd4539c418 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -50,7 +50,7 @@ endif
 LLVMLINK :=
 
 ifeq ($(JULIACODEGEN),LLVM)
-SRCS += codegen jitlayers disasm debuginfo llvm-simdloop llvm-ptls llvm-muladd llvm-late-gc-lowering llvm-lower-handlers llvm-gc-invariant-verifier llvm-propagate-addrspaces cgmemmgr
+SRCS += codegen jitlayers disasm debuginfo llvm-simdloop llvm-ptls llvm-muladd llvm-late-gc-lowering llvm-lower-handlers llvm-gc-invariant-verifier llvm-propagate-addrspaces llvm-alloc-opt cgmemmgr
 FLAGS += -I$(shell $(LLVM_CONFIG_HOST) --includedir)
 LLVM_LIBS := all
 ifeq ($(USE_POLLY),1)
diff --git a/src/ccall.cpp b/src/ccall.cpp
index 849fcd6df7..4492dd134a 100644
--- a/src/ccall.cpp
+++ b/src/ccall.cpp
@@ -2143,7 +2143,7 @@ jl_cgval_t function_sig_t::emit_a_ccall(
                 size_t rtsz = jl_datatype_size(rt);
                 assert(rtsz > 0);
                 Value *strct = emit_allocobj(ctx, rtsz, runtime_bt);
-                int boxalign = jl_gc_alignment(rtsz);
+                int boxalign = jl_datatype_align(rt);
 #ifndef JL_NDEBUG
 #if JL_LLVM_VERSION >= 40000
                 const DataLayout &DL = jl_data_layout;
diff --git a/src/cgutils.cpp b/src/cgutils.cpp
index bfe1b64684..adf2b56ca7 100644
--- a/src/cgutils.cpp
+++ b/src/cgutils.cpp
@@ -2149,25 +2149,10 @@ static Value *emit_allocobj(jl_codectx_t &ctx, size_t static_size, Value *jt)
 {
     JL_FEAT_REQUIRE(ctx, dynamic_alloc);
     JL_FEAT_REQUIRE(ctx, runtime);
-
-    int osize;
-    int offset = jl_gc_classify_pools(static_size, &osize);
     Value *ptls_ptr = emit_bitcast(ctx, ctx.ptlsStates, T_pint8);
-    Value *v;
-    if (offset < 0) {
-        Value *args[] = {ptls_ptr,
-                         ConstantInt::get(T_size, static_size + sizeof(void*))};
-        v = ctx.builder.CreateCall(prepare_call(jlalloc_big_func),
-                               ArrayRef<Value*>(args, 2));
-    }
-    else {
-        Value *pool_offs = ConstantInt::get(T_int32, offset);
-        Value *args[] = {ptls_ptr, pool_offs, ConstantInt::get(T_int32, osize)};
-        v = ctx.builder.CreateCall(prepare_call(jlalloc_pool_func),
-                               ArrayRef<Value*>(args, 3));
-    }
-    tbaa_decorate(tbaa_tag, ctx.builder.CreateStore(maybe_decay_untracked(jt), emit_typeptr_addr(ctx, v)));
-    return v;
+    return ctx.builder.CreateCall(prepare_call(jl_alloc_obj_func),
+                                  {ptls_ptr, ConstantInt::get(T_size, static_size),
+                                          maybe_decay_untracked(jt)});
 }
 
 // if ptr is NULL this emits a write barrier _back_
diff --git a/src/codegen.cpp b/src/codegen.cpp
index 7538267f3d..01b3c2c951 100644
--- a/src/codegen.cpp
+++ b/src/codegen.cpp
@@ -315,8 +315,7 @@ static Function *jlgenericfunction_func;
 static Function *jlenter_func;
 static Function *jlleave_func;
 static Function *jlegal_func;
-static Function *jlalloc_pool_func;
-static Function *jlalloc_big_func;
+static Function *jl_alloc_obj_func;
 static Function *jlisa_func;
 static Function *jlsubtype_func;
 static Function *jlapplytype_func;
@@ -6635,24 +6634,19 @@ static void init_julia_llvm_env(Module *m)
                          "jl_instantiate_type_in_env", m);
     add_named_global(jlapplytype_func, &jl_instantiate_type_in_env);
 
-    std::vector<Type*> alloc_pool_args(0);
-    alloc_pool_args.push_back(T_pint8);
-    alloc_pool_args.push_back(T_int32);
-    alloc_pool_args.push_back(T_int32);
-    jlalloc_pool_func =
-        Function::Create(FunctionType::get(T_prjlvalue, alloc_pool_args, false),
-                         Function::ExternalLinkage,
-                         "jl_gc_pool_alloc", m);
-    add_named_global(jlalloc_pool_func, &jl_gc_pool_alloc);
-
-    std::vector<Type*> alloc_big_args(0);
-    alloc_big_args.push_back(T_pint8);
-    alloc_big_args.push_back(T_size);
-    jlalloc_big_func =
-        Function::Create(FunctionType::get(T_prjlvalue, alloc_big_args, false),
-                         Function::ExternalLinkage,
-                         "jl_gc_big_alloc", m);
-    add_named_global(jlalloc_big_func, &jl_gc_big_alloc);
+    std::vector<Type*> gc_alloc_args(0);
+    gc_alloc_args.push_back(T_pint8);
+    gc_alloc_args.push_back(T_size);
+    gc_alloc_args.push_back(T_prjlvalue);
+    jl_alloc_obj_func = Function::Create(FunctionType::get(T_prjlvalue, gc_alloc_args, false),
+                                         Function::ExternalLinkage,
+                                         "julia.gc_alloc_obj");
+#if JL_LLVM_VERSION >= 50000
+    jl_alloc_obj_func->addAttribute(AttributeList::ReturnIndex, Attribute::NoAlias);
+#else
+    jl_alloc_obj_func->addAttribute(AttributeSet::ReturnIndex, Attribute::NoAlias);
+#endif
+    add_named_global(jl_alloc_obj_func, (void*)NULL, /*dllimport*/false);
 
     std::vector<Type *> dlsym_args(0);
     dlsym_args.push_back(T_pint8);
diff --git a/src/intrinsics.cpp b/src/intrinsics.cpp
index 7c9ef29df2..5b7397ddc8 100644
--- a/src/intrinsics.cpp
+++ b/src/intrinsics.cpp
@@ -325,11 +325,7 @@ static Value *emit_unbox(jl_codectx_t &ctx, Type *to, const jl_cgval_t &x, jl_va
     }
 
     int alignment;
-    if (x.isboxed) {
-        // julia's gc gives 16-byte aligned addresses
-        alignment = 16;
-    }
-    else if (jt) {
+    if (jt) {
         alignment = julia_alignment(p, jt, 0);
     }
     else {
diff --git a/src/jitlayers.cpp b/src/jitlayers.cpp
index 10f8a4c290..2f00f80dce 100644
--- a/src/jitlayers.cpp
+++ b/src/jitlayers.cpp
@@ -108,6 +108,7 @@ void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level)
 #endif
     if (opt_level == 0) {
         PM->add(createCFGSimplificationPass()); // Clean up disgusting code
+        PM->add(createAllocOptPass(false));
 #if JL_LLVM_VERSION < 50000
         PM->add(createBarrierNoopPass());
         PM->add(createLowerExcHandlersPass());
@@ -147,6 +148,7 @@ void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level)
     // effectiveness of the optimization, but should retain correctness.
 #if JL_LLVM_VERSION < 50000
     PM->add(createLowerExcHandlersPass());
+    PM->add(createAllocOptPass(true));
     PM->add(createLateLowerGCFramePass());
     // Remove dead use of ptls
     PM->add(createDeadCodeEliminationPass());
@@ -161,6 +163,12 @@ void addOptimizationPasses(legacy::PassManagerBase *PM, int opt_level)
     PM->add(createAlwaysInlinerPass()); // Respect always_inline
 #endif
 
+#if JL_LLVM_VERSION >= 50000
+    // Running `memcpyopt` between this and `sroa` seems to give `sroa` a hard time
+    // merging the `alloca` for the unboxed data and the `alloca` created by the `alloc_opt`
+    // pass.
+    PM->add(createAllocOptPass(true));
+#endif
     PM->add(createInstructionCombiningPass()); // Cleanup for scalarrepl.
     PM->add(createSROAPass());                 // Break up aggregate allocas
     PM->add(createInstructionCombiningPass()); // Cleanup for scalarrepl.
diff --git a/src/jitlayers.h b/src/jitlayers.h
index aaa11ec384..138c8f9d81 100644
--- a/src/jitlayers.h
+++ b/src/jitlayers.h
@@ -207,6 +207,7 @@ Pass *createLateLowerGCFramePass();
 Pass *createLowerExcHandlersPass();
 Pass *createGCInvariantVerifierPass(bool Strong);
 Pass *createPropagateJuliaAddrspaces();
+Pass *createAllocOptPass(bool);
 // Whether the Function is an llvm or julia intrinsic.
 static inline bool isIntrinsicFunction(Function *F)
 {
diff --git a/src/llvm-alloc-opt.cpp b/src/llvm-alloc-opt.cpp
new file mode 100644
index 0000000000..4da3c22cd4
--- /dev/null
+++ b/src/llvm-alloc-opt.cpp
@@ -0,0 +1,688 @@
+// This file is a part of Julia. License is MIT: https://julialang.org/license
+
+#define DEBUG_TYPE "alloc_opt"
+#undef DEBUG
+#include "llvm-version.h"
+
+#include <llvm/IR/Value.h>
+#include <llvm/IR/CFG.h>
+#include <llvm/IR/Function.h>
+#include <llvm/IR/Instructions.h>
+#include <llvm/IR/IntrinsicInst.h>
+#include <llvm/IR/Module.h>
+#include <llvm/IR/Operator.h>
+#include <llvm/IR/IRBuilder.h>
+#include <llvm/Pass.h>
+#include <llvm/Support/Debug.h>
+
+#include <llvm/IR/Dominators.h>
+
+#include "fix_llvm_assert.h"
+
+#include "codegen_shared.h"
+#include "julia.h"
+#include "julia_internal.h"
+
+#include <map>
+#include <set>
+
+using namespace llvm;
+
+extern std::pair<MDNode*,MDNode*> tbaa_make_child(const char *name, MDNode *parent=nullptr, bool isConstant=false);
+
+namespace {
+
+static void copyMetadata(Instruction *dest, const Instruction *src)
+{
+#if JL_LLVM_VERSION < 40000
+    if (!src->hasMetadata())
+        return;
+    SmallVector<std::pair<unsigned,MDNode*>,4> TheMDs;
+    src->getAllMetadataOtherThanDebugLoc(TheMDs);
+    for (const auto &MD : TheMDs)
+        dest->setMetadata(MD.first, MD.second);
+    dest->setDebugLoc(src->getDebugLoc());
+#else
+    dest->copyMetadata(*src);
+#endif
+}
+
+/**
+ * Promote `julia.gc_alloc_obj` which do not have escaping root to a alloca and
+ * lower other ones to real GC allocation.
+ */
+
+struct AllocOpt : public FunctionPass {
+    static char ID;
+    AllocOpt(bool opt=true)
+        : FunctionPass(ID),
+          optimize(opt)
+    {}
+
+private:
+    bool optimize;
+    LLVMContext *ctx;
+
+    const DataLayout *DL;
+
+    Function *alloc_obj;
+    Function *pool_alloc;
+    Function *big_alloc;
+    Function *ptr_from_objref;
+    Function *lifetime_start;
+    Function *lifetime_end;
+
+    Type *T_int8;
+    Type *T_int32;
+    Type *T_int64;
+    Type *T_size;
+    Type *T_pint8;
+    Type *T_pjlvalue;
+    Type *T_pjlvalue0;
+    Type *T_pjlvalue_der;
+    Type *T_ppjlvalue0;
+    Type *T_ppjlvalue_der;
+
+    MDNode *tbaa_tag;
+
+    struct CheckInstFrame {
+        Instruction *parent;
+        size_t offset;
+        Instruction::user_iterator user_it;
+        Instruction::user_iterator user_end;
+    };
+    typedef SmallVector<CheckInstFrame, 4> CheckInstStack;
+    struct ReplaceUsesFrame {
+        Instruction *orig_i;
+        Instruction *new_i;
+        SmallVector<User*,4> users;
+        size_t idx;
+        ReplaceUsesFrame(Instruction *orig_i, Instruction *new_i)
+            : orig_i(orig_i),
+              new_i(new_i),
+              users(orig_i->user_begin(), orig_i->user_end()),
+              idx(0)
+        {}
+    };
+    typedef SmallVector<ReplaceUsesFrame,4> ReplaceUsesStack;
+
+    bool doInitialization(Module &m) override;
+    bool runOnFunction(Function &F) override;
+    bool checkInst(Instruction *I, CheckInstStack &stack, std::set<Instruction*> &uses,
+                   bool &ignore_tag);
+    void replaceUsesWith(Instruction *orig_i, Instruction *new_i, ReplaceUsesStack &stack);
+    void lowerAlloc(CallInst *I, size_t sz);
+    bool isSafepoint(Instruction *inst);
+    void getAnalysisUsage(AnalysisUsage &AU) const override
+    {
+        if (optimize) {
+            FunctionPass::getAnalysisUsage(AU);
+            AU.addRequired<DominatorTreeWrapperPass>();
+            AU.addPreserved<DominatorTreeWrapperPass>();
+            AU.setPreservesCFG();
+        }
+    }
+};
+
+static void addRetNoAlias(Function *F)
+{
+#if JL_LLVM_VERSION >= 50000
+    F->addAttribute(AttributeList::ReturnIndex, Attribute::NoAlias);
+#else
+    F->addAttribute(AttributeSet::ReturnIndex, Attribute::NoAlias);
+#endif
+}
+
+bool AllocOpt::doInitialization(Module &M)
+{
+    ctx = &M.getContext();
+    DL = &M.getDataLayout();
+
+    alloc_obj = M.getFunction("julia.gc_alloc_obj");
+    if (!alloc_obj)
+        return false;
+
+    ptr_from_objref = M.getFunction("julia.pointer_from_objref");
+
+    T_pjlvalue = alloc_obj->getReturnType();
+    T_pjlvalue0 = PointerType::get(cast<PointerType>(T_pjlvalue)->getElementType(), 0);
+    T_pjlvalue_der = PointerType::get(cast<PointerType>(T_pjlvalue)->getElementType(),
+                                      AddressSpace::Derived);
+    T_ppjlvalue0 = PointerType::get(T_pjlvalue, 0);
+    T_ppjlvalue_der = PointerType::get(T_pjlvalue, AddressSpace::Derived);
+
+    T_int8 = Type::getInt8Ty(*ctx);
+    T_int32 = Type::getInt32Ty(*ctx);
+    T_int64 = Type::getInt64Ty(*ctx);
+    T_size = sizeof(void*) == 8 ? T_int64 : T_int32;
+    T_pint8 = PointerType::get(T_int8, 0);
+
+    if (!(pool_alloc = M.getFunction("jl_gc_pool_alloc"))) {
+        std::vector<Type*> alloc_pool_args(0);
+        alloc_pool_args.push_back(T_pint8);
+        alloc_pool_args.push_back(T_int32);
+        alloc_pool_args.push_back(T_int32);
+        pool_alloc = Function::Create(FunctionType::get(T_pjlvalue, alloc_pool_args, false),
+                                      Function::ExternalLinkage, "jl_gc_pool_alloc", &M);
+        addRetNoAlias(pool_alloc);
+    }
+    if (!(big_alloc = M.getFunction("jl_gc_big_alloc"))) {
+        std::vector<Type*> alloc_big_args(0);
+        alloc_big_args.push_back(T_pint8);
+        alloc_big_args.push_back(T_size);
+        big_alloc = Function::Create(FunctionType::get(T_pjlvalue, alloc_big_args, false),
+                                     Function::ExternalLinkage, "jl_gc_big_alloc", &M);
+        addRetNoAlias(big_alloc);
+    }
+
+#if JL_LLVM_VERSION >= 50000
+    lifetime_start = Intrinsic::getDeclaration(&M, Intrinsic::lifetime_start, { T_pint8 });
+    lifetime_end = Intrinsic::getDeclaration(&M, Intrinsic::lifetime_end, { T_pint8 });
+#else
+    lifetime_start = Intrinsic::getDeclaration(&M, Intrinsic::lifetime_start);
+    lifetime_end = Intrinsic::getDeclaration(&M, Intrinsic::lifetime_end);
+#endif
+
+    MDNode *tbaa_data;
+    MDNode *tbaa_data_scalar;
+    std::tie(tbaa_data, tbaa_data_scalar) = tbaa_make_child("jtbaa_data");
+    tbaa_tag = tbaa_make_child("jtbaa_tag", tbaa_data_scalar).first;
+
+    return true;
+}
+
+bool AllocOpt::checkInst(Instruction *I, CheckInstStack &stack, std::set<Instruction*> &uses,
+                         bool &ignore_tag)
+{
+    if (I->user_empty())
+        return true;
+    CheckInstFrame cur{I, 0, I->user_begin(), I->user_end()};
+    stack.clear();
+    uses.clear();
+
+    // Recursion
+    auto push_inst = [&] (Instruction *inst) {
+        if (cur.user_it != cur.user_end)
+            stack.push_back(cur);
+        cur.parent = inst;
+        cur.user_it = inst->user_begin();
+        cur.user_end = inst->user_end();
+    };
+
+    auto check_inst = [&] (Instruction *inst) {
+        if (isa<LoadInst>(inst))
+            return true;
+        if (auto call = dyn_cast<CallInst>(inst)) {
+            // TODO: on LLVM 5.0 we may need to handle certain llvm intrinsics
+            // including `memcpy`, `memset` etc. We might also need to handle
+            // `memcmp` by coverting to our own intrinsic and lower it after the gc root pass.
+            if (ptr_from_objref && ptr_from_objref == call->getCalledFunction())
+                return true;
+            // Only use in argument counts, use in operand bundle doesn't since it cannot escape.
+            for (auto &arg: call->arg_operands()) {
+                if (dyn_cast<Instruction>(&arg) == cur.parent) {
+                    return false;
+                }
+            }
+            if (call->getNumOperandBundles() != 1)
+                return false;
+            auto obuse = call->getOperandBundleAt(0);
+            if (obuse.getTagName() != "jl_roots")
+                return false;
+            return true;
+        }
+        if (auto store = dyn_cast<StoreInst>(inst)) {
+            auto storev = store->getValueOperand();
+            // Only store value count
+            if (storev == cur.parent)
+                return false;
+            // There's GC root in this object.
+            if (auto ptrtype = dyn_cast<PointerType>(storev->getType())) {
+                if (ptrtype->getAddressSpace() == AddressSpace::Tracked) {
+                    return false;
+                }
+            }
+            return true;
+        }
+        if (isa<AddrSpaceCastInst>(inst) || isa<BitCastInst>(inst)) {
+            push_inst(inst);
+            return true;
+        }
+        if (auto gep = dyn_cast<GetElementPtrInst>(inst)) {
+            APInt apoffset(sizeof(void*) * 8, cur.offset, true);
+            if (ignore_tag && (!gep->accumulateConstantOffset(*DL, apoffset) ||
+                               apoffset.isNegative()))
+                ignore_tag = false;
+            push_inst(inst);
+            cur.offset = apoffset.getLimitedValue();
+            return true;
+        }
+        return false;
+    };
+
+    while (true) {
+        assert(cur.user_it != cur.user_end);
+        auto user = *cur.user_it;
+        auto inst = dyn_cast<Instruction>(user);
+        ++cur.user_it;
+        if (!inst)
+            return false;
+        if (!check_inst(inst))
+            return false;
+        uses.insert(inst);
+        if (cur.user_it == cur.user_end) {
+            if (stack.empty())
+                return true;
+            cur = stack.back();
+            stack.pop_back();
+        }
+    }
+}
+
+// Both arguments should be pointer of the same type but possibly different address spaces
+// `orig_i` is always in addrspace 0.
+// This function needs to handle all cases `AllocOpt::checkInst` can handle.
+// This function should not erase any safepoint
+void AllocOpt::replaceUsesWith(Instruction *orig_inst, Instruction *new_inst,
+                               ReplaceUsesStack &stack)
+{
+    auto simple_replace = [&] (Instruction *orig_i, Instruction *new_i) {
+        if (orig_i->user_empty()) {
+            if (orig_i != orig_inst)
+                orig_i->eraseFromParent();
+            return true;
+        }
+        Type *orig_t = orig_i->getType();
+        Type *new_t = new_i->getType();
+        if (orig_t == new_t) {
+            orig_i->replaceAllUsesWith(new_i);
+            if (orig_i != orig_inst)
+                orig_i->eraseFromParent();
+            return true;
+        }
+        return false;
+    };
+    if (simple_replace(orig_inst, new_inst))
+        return;
+    stack.clear();
+    stack.emplace_back(orig_inst, new_inst);
+    ReplaceUsesFrame *cur = &stack[0];
+    auto finish_cur = [&] () {
+        assert(cur->orig_i->user_empty());
+        if (cur->orig_i != orig_inst) {
+            cur->orig_i->eraseFromParent();
+        }
+    };
+    auto push_frame = [&] (Instruction *orig_i, Instruction *new_i) {
+        if (simple_replace(orig_i, new_i))
+            return;
+        stack.emplace_back(orig_i, new_i);
+        cur = &stack.back();
+    };
+    auto replace_inst = [&] (Instruction *user) {
+        Instruction *orig_i = cur->orig_i;
+        Instruction *new_i = cur->new_i;
+        if (isa<LoadInst>(user) || isa<StoreInst>(user)) {
+            user->replaceUsesOfWith(orig_i, new_i);
+        }
+        else if (auto call = dyn_cast<CallInst>(user)) {
+            if (ptr_from_objref && ptr_from_objref == call->getCalledFunction()) {
+                call->replaceAllUsesWith(new_i);
+                call->eraseFromParent();
+                return;
+            }
+            // remove from operand bundle
+            Type *new_t = new_i->getType();
+            user->replaceUsesOfWith(orig_i, ConstantPointerNull::get(cast<PointerType>(new_t)));
+        }
+        else if (isa<AddrSpaceCastInst>(user) || isa<BitCastInst>(user)) {
+            auto cast_t = PointerType::get(cast<PointerType>(user->getType())->getElementType(),
+                                           0);
+            auto replace_i = new_i;
+            Type *orig_t = orig_i->getType();
+            if (cast_t != orig_t)
+                replace_i = new BitCastInst(replace_i, cast_t, "", user);
+            push_frame(user, replace_i);
+        }
+        else if (auto gep = dyn_cast<GetElementPtrInst>(user)) {
+            Instruction *new_gep;
+            SmallVector<Value *, 4> IdxOperands(gep->idx_begin(), gep->idx_end());
+            if (gep->isInBounds()) {
+                new_gep = GetElementPtrInst::CreateInBounds(gep->getSourceElementType(),
+                                                            new_i, IdxOperands,
+                                                            gep->getName(), gep);
+            }
+            else {
+                new_gep = GetElementPtrInst::Create(gep->getSourceElementType(),
+                                                    new_i, IdxOperands,
+                                                    gep->getName(), gep);
+            }
+            copyMetadata(new_gep, gep);
+            push_frame(gep, new_gep);
+        }
+        else {
+            abort();
+        }
+    };
+
+    while (true) {
+        assert(cur->idx < cur->users.size());
+        auto user = cast<Instruction>(cur->users[cur->idx]);
+        cur->idx++;
+        replace_inst(user);
+        while (cur->idx >= cur->users.size()) {
+            finish_cur();
+            stack.pop_back();
+            if (stack.empty())
+                return;
+            cur = &stack.back();
+        }
+    }
+}
+
+void AllocOpt::lowerAlloc(CallInst *I, size_t sz)
+{
+    int osize;
+    int offset = jl_gc_classify_pools(sz, &osize);
+    auto ptls = I->getArgOperand(0);
+    CallInst *newI;
+    if (offset < 0) {
+        newI = CallInst::Create(big_alloc, {ptls, ConstantInt::get(T_size, sz + sizeof(void*))},
+                                None, "", I);
+    }
+    else {
+        auto pool_offs = ConstantInt::get(T_int32, offset);
+        auto pool_osize = ConstantInt::get(T_int32, osize);
+        newI = CallInst::Create(pool_alloc, {ptls, pool_offs, pool_osize}, None, "", I);
+    }
+    auto tag = I->getArgOperand(2);
+    copyMetadata(newI, I);
+    const auto &dbg = I->getDebugLoc();
+    auto derived = new AddrSpaceCastInst(newI, T_pjlvalue_der, "", I);
+    derived->setDebugLoc(dbg);
+    auto cast = new BitCastInst(derived, T_ppjlvalue_der, "", I);
+    cast->setDebugLoc(dbg);
+    auto tagaddr = GetElementPtrInst::Create(T_pjlvalue, cast, {ConstantInt::get(T_size, -1)},
+                                             "", I);
+    tagaddr->setDebugLoc(dbg);
+    auto store = new StoreInst(tag, tagaddr, I);
+    store->setMetadata(LLVMContext::MD_tbaa, tbaa_tag);
+    store->setDebugLoc(dbg);
+    I->replaceAllUsesWith(newI);
+}
+
+bool AllocOpt::isSafepoint(Instruction *inst)
+{
+    auto call = dyn_cast<CallInst>(inst);
+    if (!call)
+        return false;
+    if (isa<IntrinsicInst>(call))
+        return false;
+    if (auto callee = call->getCalledFunction()) {
+        // Known functions emitted in codegen that are not safepoints
+        if (callee == ptr_from_objref || callee->getName() == "memcmp") {
+            return false;
+        }
+    }
+    return true;
+}
+
+bool AllocOpt::runOnFunction(Function &F)
+{
+    if (!alloc_obj)
+        return false;
+    std::map<CallInst*,size_t> allocs;
+    for (auto &bb: F) {
+        for (auto &I: bb) {
+            auto call = dyn_cast<CallInst>(&I);
+            if (!call)
+                continue;
+            auto callee = call->getCalledFunction();
+            if (!callee)
+                continue;
+            size_t sz;
+            if (callee == alloc_obj) {
+                assert(call->getNumArgOperands() == 3);
+                sz = (size_t)cast<ConstantInt>(call->getArgOperand(1))->getZExtValue();
+            }
+            else {
+                continue;
+            }
+            allocs[call] = sz;
+        }
+    }
+
+    auto &entry = F.getEntryBlock();
+    auto first = &entry.front();
+    CheckInstStack check_stack;
+    ReplaceUsesStack replace_stack;
+    std::set<Instruction*> alloc_uses;
+    std::map<BasicBlock*,Instruction*> first_safepoint;
+    auto get_first_safepoint = [&] (BasicBlock *bb) {
+        auto it = first_safepoint.find(bb);
+        if (it != first_safepoint.end())
+            return it->second;
+        Instruction *first = nullptr;
+        for (auto &I: *bb) {
+            if (isSafepoint(&I)) {
+                first = &I;
+                break;
+            }
+        }
+        first_safepoint[bb] = first;
+        return first;
+    };
+    auto insert_lifetime_end = [&] (Instruction *ptr, Constant *sz, Instruction *insert) {
+        BasicBlock::iterator it(insert);
+        BasicBlock::iterator begin(insert->getParent()->begin());
+        while (it != begin) {
+            --it;
+            if (auto II = dyn_cast<IntrinsicInst>(&*it)) {
+                if (II->getIntrinsicID() == Intrinsic::lifetime_start ||
+                    II->getIntrinsicID() == Intrinsic::lifetime_end) {
+                    insert = II;
+                    continue;
+                }
+            }
+            break;
+        }
+        CallInst::Create(lifetime_end, {sz, ptr}, "", insert);
+    };
+    struct BBPredFrame {
+        BasicBlock *bb;
+        pred_iterator p_cur;
+        pred_iterator p_end;
+        BBPredFrame(BasicBlock *bb)
+            : bb(bb),
+              p_cur(pred_begin(bb)),
+              p_end(pred_end(bb))
+        {}
+    };
+    SmallVector<BBPredFrame,4> bb_stack;
+    auto insert_lifetime = [&] (Instruction *ptr, Constant *sz, Instruction *orig) {
+        CallInst::Create(lifetime_start, {sz, ptr}, "", orig);
+        BasicBlock *def = orig->getParent();
+        std::set<BasicBlock*> bbs{def};
+        auto &DT = getAnalysis<DominatorTreeWrapperPass>().getDomTree();
+        // Collect all BB where the allocation is live
+        for (auto use: alloc_uses) {
+            auto bb = use->getParent();
+            if (!bbs.insert(bb).second)
+                continue;
+            bb_stack.clear();
+            BBPredFrame cur{bb};
+            while (true) {
+                assert(cur.p_cur != cur.p_end);
+                auto pred = *cur.p_cur;
+                ++cur.p_cur;
+                if (bbs.insert(pred).second) {
+                    if (cur.p_cur != cur.p_end)
+                        bb_stack.push_back(cur);
+                    cur = BBPredFrame(pred);
+                }
+                if (cur.p_cur == cur.p_end) {
+                    if (bb_stack.empty())
+                        break;
+                    cur = bb_stack.back();
+                    bb_stack.pop_back();
+                }
+            }
+        }
+        // For each BB, find the first instruction(s) where the allocation is possibly dead.
+        // If all successors are live, then there isn't one.
+        // If all successors are dead, then it's the first instruction after the last use
+        // within the BB.
+        // If some successors are live and others are dead, it's the first instruction in
+        // the successors that are dead.
+        std::vector<Instruction*> first_dead;
+        for (auto bb: bbs) {
+            bool has_use = false;
+            for (auto succ: successors(bb)) {
+                // def is the only bb in bbs that's not dominated by orig
+                if (succ != def && bbs.find(succ) != bbs.end()) {
+                    has_use = true;
+                    break;
+                }
+            }
+            if (has_use) {
+                for (auto succ: successors(bb)) {
+                    if (bbs.find(succ) == bbs.end()) {
+                        first_dead.push_back(&*succ->begin());
+                    }
+                }
+            }
+            else {
+                for (auto it = bb->rbegin(), end = bb->rend(); it != end; ++it) {
+                    if (alloc_uses.find(&*it) != alloc_uses.end()) {
+                        --it;
+                        first_dead.push_back(&*it);
+                        break;
+                    }
+                }
+            }
+        }
+        bbs.clear();
+        // There can/need only be one lifetime.end for each allocation in each bb, use bbs
+        // to record that.
+        // Iterate through the first dead and find the first safepoint following each of them.
+        while (!first_dead.empty()) {
+            auto I = first_dead.back();
+            first_dead.pop_back();
+            auto bb = I->getParent();
+            if (!bbs.insert(bb).second)
+                continue;
+            if (I == &*bb->begin()) {
+                // The there's no use in or after this bb. If this bb is not dominated by
+                // the def then it has to be dead on entering this bb.
+                // Otherwise, there could be use that we don't track
+                // before hitting the next safepoint.
+                if (!DT.dominates(orig, bb)) {
+                    insert_lifetime_end(ptr, sz, &*bb->getFirstInsertionPt());
+                    continue;
+                }
+                else if (auto insert = get_first_safepoint(bb)) {
+                    insert_lifetime_end(ptr, sz, insert);
+                }
+            }
+            else {
+                assert(DT.dominates(orig, I));
+                BasicBlock::iterator it(I);
+                BasicBlock::iterator end = bb->end();
+                bool safepoint_found = false;
+                for (; it != end; ++it) {
+                    auto insert = &*it;
+                    if (isSafepoint(insert)) {
+                        insert_lifetime_end(ptr, sz, insert);
+                        safepoint_found = true;
+                        break;
+                    }
+                }
+                if (safepoint_found) {
+                    continue;
+                }
+            }
+            for (auto succ: successors(bb)) {
+                first_dead.push_back(&*succ->begin());
+            }
+        }
+    };
+    for (auto it: allocs) {
+        bool ignore_tag = true;
+        auto orig = it.first;
+        if (optimize && checkInst(orig, check_stack, alloc_uses, ignore_tag)) {
+            // The allocation does not escape or get used in a phi node so none of the derived
+            // SSA from it are live when we run the allocation again.
+            // It is now safe to promote the allocation to an entry block alloca.
+            size_t sz = it.second;
+            size_t align = 1;
+            // TODO make codegen handling of alignment consistent and pass that as a parameter
+            // to the allocation function directly.
+            if (!ignore_tag) {
+                align = sz <= 8 ? 8 : 16;
+                sz += align;
+            }
+            else if (sz >= 16) {
+                align = 16;
+            }
+            else if (sz >= 8) {
+                align = 8;
+            }
+            else if (sz >= 4) {
+                align = 4;
+            }
+            else if (sz >= 2) {
+                align = 2;
+            }
+            const auto &dbg = orig->getDebugLoc();
+#if JL_LLVM_VERSION >= 50000
+            Instruction *ptr = new AllocaInst(T_int8, 0, ConstantInt::get(T_int32, sz),
+                                              align, "", first);
+#else
+            Instruction *ptr = new AllocaInst(T_int8, ConstantInt::get(T_int32, sz),
+                                              align, "", first);
+#endif
+            insert_lifetime(ptr, ConstantInt::get(T_int64, sz), orig);
+            ptr->setDebugLoc(dbg);
+            if (!ignore_tag) {
+                ptr = GetElementPtrInst::CreateInBounds(T_size, ptr,
+                                                        {ConstantInt::get(T_int32, align)}, "",
+                                                        first);
+                ptr->setDebugLoc(dbg);
+            }
+            auto cast = new BitCastInst(ptr, T_pjlvalue0, "", first);
+            cast->setDebugLoc(dbg);
+            // Someone might be reading the tag, initialize it.
+            if (!ignore_tag) {
+                auto tag = orig->getArgOperand(2);
+                auto cast2 = new BitCastInst(ptr, T_ppjlvalue0, "", orig);
+                cast2->setDebugLoc(dbg);
+                auto tagaddr = GetElementPtrInst::Create(T_pjlvalue, cast,
+                                                         {ConstantInt::get(T_size, -1)},
+                                                         "", orig);
+                tagaddr->setDebugLoc(dbg);
+                auto store = new StoreInst(tag, tagaddr, orig);
+                store->setMetadata(LLVMContext::MD_tbaa, tbaa_tag);
+                store->setDebugLoc(dbg);
+            }
+            replaceUsesWith(orig, cast, replace_stack);
+        }
+        else {
+            lowerAlloc(orig, it.second);
+        }
+    }
+    for (auto it: allocs)
+        it.first->eraseFromParent();
+    return true;
+}
+
+char AllocOpt::ID = 0;
+static RegisterPass<AllocOpt> X("AllocOpt", "Promote heap allocation to stack",
+                                false /* Only looks at CFG */,
+                                false /* Analysis Pass */);
+
+}
+
+Pass *createAllocOptPass(bool opt)
+{
+    return new AllocOpt(opt);
+}
diff --git a/test/codegen.jl b/test/codegen.jl
index da80ff1661..35220c772b 100644
--- a/test/codegen.jl
+++ b/test/codegen.jl
@@ -135,3 +135,18 @@ if opt_level > 0
     @test contains(compare_large_struct_ir, "call i32 @memcmp")
     @test !contains(compare_large_struct_ir, "%gcframe")
 end
+
+function two_breakpoint(a::Float64)
+    ccall(:jl_breakpoint, Void, (Ref{Float64},), a)
+    ccall(:jl_breakpoint, Void, (Ref{Float64},), a)
+end
+
+if opt_level > 0
+    @test !contains(get_llvm((a)->ccall(:jl_breakpoint, Void, (Ref{Float64},), a),
+                             Tuple{Float64}), "jl_gc_pool_alloc")
+    @test contains(get_llvm((a)->ccall(:jl_breakpoint, Void, (Ref{Any},), a),
+                            Tuple{Float64}), "jl_gc_pool_alloc")
+    two_breakpoint_ir = get_llvm(two_breakpoint, Tuple{Float64})
+    @test !contains(two_breakpoint_ir, "jl_gc_pool_alloc")
+    @test contains(two_breakpoint_ir, "llvm.lifetime.end")
+end
-- 
2.13.2

