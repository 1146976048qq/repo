From 0d282ce244307b06bef3ced8deca1e7b00d0bf07 Mon Sep 17 00:00:00 2001
From: Yichao Yu <yyc1992@gmail.com>
Date: Sat, 13 May 2017 20:51:24 -0400
Subject: [PATCH 3/9] Add X86 CPU name and feature detection

Also implement the API needed by other part of the runtime,
especially LLVM JIT, cloning pass and sysimg initialization.

Most of the detection (both name and features) code is copied from LLVM.
However, it's very hard for us to use LLVM because there are informations we need that
is not provided by LLVM (some of which is non-trivial to expose in a target independent way),
including,

1. Feature dependencies
2. Features related to a CPU name
3. Feature name validation (needed when we expose this to julia code)
4. Effect on ABI (vector register size)
5. Serialization format
6. Cloning heuristic

Additionally, the detection code itself is only a small part of the code for each arch
and we need to support multiple LLVM versions so copying the LLVM code shouldn't cause too
much problem by itself.
---
 src/Makefile          |   1 +
 src/features_x86.h    |  91 +++++
 src/julia_internal.h  |   5 -
 src/processor.cpp     | 877 +++++++++++++++++++++++++++++++++++++++++-----
 src/processor.h       | 200 +++++++++++
 src/processor_x86.cpp | 948 ++++++++++++++++++++++++++++++++++++++++++++++++++
 src/runtime_ccall.cpp |  39 ++-
 7 files changed, 2071 insertions(+), 90 deletions(-)
 create mode 100644 src/features_x86.h
 create mode 100644 src/processor.h
 create mode 100644 src/processor_x86.cpp

diff --git a/src/Makefile b/src/Makefile
index 439f62acb9..99f84cdd25 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -183,6 +183,7 @@ $(BUILDDIR)/julia_flisp.boot: $(addprefix $(SRCDIR)/,jlfrontend.scm flisp/aliase
 $(BUILDDIR)/ast.o $(BUILDDIR)/ast.dbg.obj: $(BUILDDIR)/julia_flisp.boot.inc $(SRCDIR)/flisp/*.h
 $(BUILDDIR)/codegen.o $(BUILDDIR)/codegen.dbg.obj: $(addprefix $(SRCDIR)/,\
 	intrinsics.cpp jitlayers.h intrinsics.h debuginfo.h codegen_shared.h cgutils.cpp ccall.cpp abi_*.cpp)
+$(BUILDDIR)/processor.o $(BUILDDIR)/processor.dbg.obj: $(addprefix $(SRCDIR)/,processor_*.cpp processor.h features_*.h)
 $(BUILDDIR)/anticodegen.o $(BUILDDIR)/anticodegen.dbg.obj: $(SRCDIR)/intrinsics.h
 $(BUILDDIR)/debuginfo.o $(BUILDDIR)/debuginfo.dbg.obj: $(SRCDIR)/debuginfo.h
 $(BUILDDIR)/disasm.o $(BUILDDIR)/disasm.dbg.obj: $(SRCDIR)/debuginfo.h
diff --git a/src/features_x86.h b/src/features_x86.h
new file mode 100644
index 0000000000..909d5aa019
--- /dev/null
+++ b/src/features_x86.h
@@ -0,0 +1,91 @@
+// This file is a part of Julia. License is MIT: https://julialang.org/license
+
+#ifdef _CPU_X86_
+// avx is unusable on 32bit before LLVM 5.0 due to LLVM bug (try to encode too many registers)
+#define JL_X86_AVX_MIN_VER 50000
+#else
+#define JL_X86_AVX_MIN_VER 0
+#endif
+
+// X86 features definition
+// EAX=1: ECX
+JL_FEATURE_DEF(sse3, 0, 0)
+JL_FEATURE_DEF(pclmul, 1, 0)
+JL_FEATURE_DEF(ssse3, 9, 0)
+JL_FEATURE_DEF(fma, 12, JL_X86_AVX_MIN_VER)
+JL_FEATURE_DEF(cx16, 13, 0)
+JL_FEATURE_DEF_NAME(sse41, 19, 0, "sse4.1")
+JL_FEATURE_DEF_NAME(sse42, 20, 0, "sse4.2")
+JL_FEATURE_DEF(movbe, 22, 0)
+JL_FEATURE_DEF(popcnt, 23, 0)
+JL_FEATURE_DEF(aes, 25, 0)
+JL_FEATURE_DEF(xsave, 26, 0)
+JL_FEATURE_DEF(avx, 28, JL_X86_AVX_MIN_VER)
+JL_FEATURE_DEF(f16c, 29, JL_X86_AVX_MIN_VER)
+JL_FEATURE_DEF(rdrnd, 30, 0)
+
+// EAX=1: EDX
+// JL_FEATURE_DEF(, 32 + ?, ????)
+
+// EAX=7,ECX=0: EBX
+JL_FEATURE_DEF(fsgsbase, 32 * 2 + 0, 0)
+// JL_FEATURE_DEF(sgx, 32 * 2 + 2, 0) // Disable for now since it's very hard to detect
+JL_FEATURE_DEF(bmi, 32 * 2 + 3, 0)
+// JL_FEATURE_DEF(hle, 32 * 2 + 4, 0) // Not used and gone in LLVM 5.0
+JL_FEATURE_DEF(avx2, 32 * 2 + 5, JL_X86_AVX_MIN_VER)
+JL_FEATURE_DEF(bmi2, 32 * 2 + 8, 0)
+// JL_FEATURE_DEF(invpcid, 32 * 2 + 10, 0) // Not used and gone in LLVM 5.0
+JL_FEATURE_DEF(rtm, 32 * 2 + 11, 0)
+JL_FEATURE_DEF(mpx, 32 * 2 + 14, 0)
+// Disable avx512 pre-5.0 since it can't handle address space
+JL_FEATURE_DEF(avx512f, 32 * 2 + 16, 50000)
+JL_FEATURE_DEF(avx512dq, 32 * 2 + 17, 50000)
+JL_FEATURE_DEF(rdseed, 32 * 2 + 18, 0)
+JL_FEATURE_DEF(adx, 32 * 2 + 19, 0)
+// JL_FEATURE_DEF(smap, 32 * 2 + 20, 0) // Not used and gone in LLVM 5.0
+JL_FEATURE_DEF(avx512ifma, 32 * 2 + 21, 50000)
+// JL_FEATURE_DEF(pcommit, 32 * 2 + 22, 0) // Deprecated
+JL_FEATURE_DEF(clflushopt, 32 * 2 + 23, 0)
+JL_FEATURE_DEF(clwb, 32 * 2 + 24, 0)
+JL_FEATURE_DEF(avx512pf, 32 * 2 + 26, 50000)
+JL_FEATURE_DEF(avx512er, 32 * 2 + 27, 50000)
+JL_FEATURE_DEF(avx512cd, 32 * 2 + 28, 50000)
+JL_FEATURE_DEF(sha, 32 * 2 + 29, 0)
+JL_FEATURE_DEF(avx512bw, 32 * 2 + 30, 50000)
+JL_FEATURE_DEF(avx512vl, 32 * 2 + 31, 50000)
+
+// EAX=7,ECX=0: ECX
+JL_FEATURE_DEF(prefetchwt1, 32 * 3 + 0, 0)
+JL_FEATURE_DEF(avx512vbmi, 32 * 3 + 1, 50000)
+JL_FEATURE_DEF(pku, 32 * 3 + 4, 0) // ospke
+JL_FEATURE_DEF(avx512vpopcntdq, 32 * 3 + 14, 50000)
+
+// EAX=7,ECX=0: EDX
+// JL_FEATURE_DEF(avx512_4vnniw, 32 * 4 + 2, ?????)
+// JL_FEATURE_DEF(avx512_4fmaps, 32 * 4 + 3, ?????)
+
+// EAX=0x80000001: ECX
+#ifdef _CPU_X86_64_
+// ignore sahf on 32bit x86 since it is required
+JL_FEATURE_DEF(sahf, 32 * 5 + 0, 0)
+#endif
+JL_FEATURE_DEF(lzcnt, 32 * 5 + 5, 0)
+JL_FEATURE_DEF(sse4a, 32 * 5 + 6, 0)
+JL_FEATURE_DEF(prfchw, 32 * 5 + 8, 0)
+JL_FEATURE_DEF(xop, 32 * 5 + 11, JL_X86_AVX_MIN_VER)
+JL_FEATURE_DEF(lwp, 32 * 5 + 15, 50000)
+JL_FEATURE_DEF(fma4, 32 * 5 + 16, JL_X86_AVX_MIN_VER)
+JL_FEATURE_DEF(tbm, 32 * 5 + 21, 0)
+JL_FEATURE_DEF(mwaitx, 32 * 5 + 29, 0)
+
+// EAX=0x80000001: EDX
+// 3dnow is here but we don't care...
+// JL_FEATURE_DEF(, 32 * 6 + ?, ?????)
+
+// EAX=0xd: EAX
+JL_FEATURE_DEF(xsaveopt, 32 * 7 + 0, 0)
+JL_FEATURE_DEF(xsavec, 32 * 7 + 1, 0)
+JL_FEATURE_DEF(xsaves, 32 * 7 + 3, 0)
+
+// EAX=0x80000008: EBX
+JL_FEATURE_DEF(clzero, 32 * 8 + 0, 50000)
diff --git a/src/julia_internal.h b/src/julia_internal.h
index ece5afc1b9..8d1a44c658 100644
--- a/src/julia_internal.h
+++ b/src/julia_internal.h
@@ -734,11 +734,6 @@ void *jl_dlopen_soname(const char *pfx, size_t n, unsigned flags);
 // libuv wrappers:
 JL_DLLEXPORT int jl_fs_rename(const char *src_path, const char *dst_path);
 
-#if defined(_CPU_X86_) || defined(_CPU_X86_64_)
-JL_DLLEXPORT void jl_cpuid(int32_t CPUInfo[4], int32_t InfoType);
-JL_DLLEXPORT void jl_cpuidex(int32_t CPUInfo[4], int32_t InfoType, int32_t subInfoType);
-#endif
-
 #ifdef SEGV_EXCEPTION
 extern JL_DLLEXPORT jl_value_t *jl_segv_exception;
 #endif
diff --git a/src/processor.cpp b/src/processor.cpp
index d4078d680a..37ece49703 100644
--- a/src/processor.cpp
+++ b/src/processor.cpp
@@ -2,112 +2,813 @@
 
 // Processor feature detection
 
+#include "processor.h"
+
 #include "julia.h"
 #include "julia_internal.h"
 
-extern "C" {
+#include <map>
+#include <algorithm>
 
-#if defined(_CPU_X86_) || defined(_CPU_X86_64_)
+#include "llvm-version.h"
+#include <llvm/ADT/StringRef.h>
+#include <llvm/Support/MathExtras.h>
+
+#include "julia_assert.h"
+
+// CPU target string is a list of strings separated by `;` each string starts with a CPU
+// or architecture name and followed by an optional list of features separated by `,`.
+// A "generic" or empty CPU name means the basic required feature set of the target ISA
+// which is at least the architecture the C/C++ runtime is compiled with.
+
+// CPU dispatch needs to determine the version to be used by the sysimg as well as
+// the target and feature used by the JIT. Currently the only limitation on JIT target
+// and feature is matching register size between the sysimg and JIT so that SIMD vectors
+// can be passed correctly. This means disabling AVX and AVX2 if AVX was not enabled
+// in sysimg and disabling AVX512 if it was not enabled in sysimg.
+// This also possibly means that SVE needs to be disabled on AArch64 if sysimg doesn't have it
+// enabled.
+
+// CPU dispatch starts by first deciding the max feature set and CPU requested for JIT.
+// This is the host or the target specified on the command line with features unavailable
+// on the host disabled. All sysimg targets that require features not available in this set
+// will be ignored.
+
+// The next step is matching CPU name.
+// If exact name match with compatible feature set exists, all versions without name match
+// are ignored.
+// This step will query LLVM first so it can accept CPU names that is recognized by LLVM but
+// not by us (yet) when LLVM is enabled.
 
-// CPUID
+// If there are still more than one candidates, a feature match is performed.
+// The ones with the largest register size will be used
+// (i.e. AVX512 > AVX2/AVX > SSE, SVE > ASIMD). If there's a tie, the one with the most features
+// enabled will be used. If there's still a tie the one that appears later in the list will be
+// used. (i.e. the order in the version list is significant in this case).
 
-JL_DLLEXPORT void jl_cpuid(int32_t CPUInfo[4], int32_t InfoType)
+// Features that are not recognized will be passed to LLVM directly during codegen
+// but ignored otherwise.
+
+// Two special features are supported:
+// 1. `clone_all`
+//
+//     This forces the target to have all functions in sysimg cloned.
+//     When used in negative form (i.e. `-clone_all`), this disables full clone that's
+//     enabled by default for certain targets.
+//
+// 2. `base([0-9]*)`
+//
+//     This specifies the (0-based) base target index. The base target is the target
+//     that the current target is based on, i.e. the functions that are not being cloned
+//     will use the version in the base target. This option causes the base target to be
+//     fully cloned (as if `clone_all` is specified for it) if it is not the default target (0).
+//     The index can only be smaller than the current index.
+
+bool jl_processor_print_help = false;
+
+namespace {
+
+// Helper functions to test/set feature bits
+
+template<typename T1, typename T2, typename T3>
+static inline bool test_bits(T1 v, T2 mask, T3 test)
 {
-#if defined _MSC_VER
-    __cpuid(CPUInfo, InfoType);
-#else
-    __asm__ __volatile__ (
-#if defined(__i386__) && defined(__PIC__)
-        "xchg %%ebx, %%esi;"
-        "cpuid;"
-        "xchg %%esi, %%ebx;" :
-        "=S" (CPUInfo[1]),
-#else
-        "cpuid" :
-        "=b" (CPUInfo[1]),
-#endif
-        "=a" (CPUInfo[0]),
-        "=c" (CPUInfo[2]),
-        "=d" (CPUInfo[3]) :
-        "a" (InfoType)
-        );
-#endif
+    return T3(v & mask) == test;
 }
 
-JL_DLLEXPORT void jl_cpuidex(int32_t CPUInfo[4], int32_t InfoType, int32_t subInfoType)
+template<typename T1, typename T2>
+static inline bool test_all_bits(T1 v, T2 mask)
 {
-#if defined _MSC_VER
-    __cpuidex(CPUInfo, InfoType, subInfoType);
-#else
-    __asm__ __volatile__ (
-#if defined(__i386__) && defined(__PIC__)
-        "xchg %%ebx, %%esi;"
-        "cpuid;"
-        "xchg %%esi, %%ebx;" :
-        "=S" (CPUInfo[1]),
-#else
-        "cpuid" :
-        "=b" (CPUInfo[1]),
-#endif
-        "=a" (CPUInfo[0]),
-        "=c" (CPUInfo[2]),
-        "=d" (CPUInfo[3]) :
-        "a" (InfoType),
-        "c" (subInfoType)
-        );
-#endif
+    return test_bits(v, mask, mask);
+}
+
+template<typename T1, typename T2>
+static inline bool test_nbit(const T1 &bits, T2 _bitidx)
+{
+    auto bitidx = static_cast<uint32_t>(_bitidx);
+    auto u32idx = bitidx / 32;
+    auto bit = bitidx % 32;
+    return (bits[u32idx] & (1 << bit)) != 0;
+}
+
+template<typename T>
+static inline void unset_bits(T &bits)
+{
+    (void)bits;
 }
 
-// -- set/clear the FZ/DAZ flags on x86 & x86-64 --
-static uint32_t get_subnormal_flags(void)
+template<typename T, typename T1, typename... Rest>
+static inline void unset_bits(T &bits, T1 _bitidx, Rest... rest)
 {
-    // CPU capabilities not yet inspected.
-    int32_t info[4];
-    jl_cpuid(info, 0);
-    if (info[0] >= 1) {
-        jl_cpuid(info, 1);
-        if (info[3] & (1 << 26)) {
-            // SSE2 supports both FZ and DAZ
-            return 0x00008040;
+    auto bitidx = static_cast<uint32_t>(_bitidx);
+    auto u32idx = bitidx / 32;
+    auto bit = bitidx % 32;
+    bits[u32idx] = bits[u32idx] & ~uint32_t(1 << bit);
+    unset_bits(bits, rest...);
+}
+
+template<typename T, typename T1>
+static inline void set_bit(T &bits, T1 _bitidx, bool val)
+{
+    auto bitidx = static_cast<uint32_t>(_bitidx);
+    auto u32idx = bitidx / 32;
+    auto bit = bitidx % 32;
+    if (val) {
+        bits[u32idx] = bits[u32idx] | uint32_t(1 << bit);
+    }
+    else {
+        bits[u32idx] = bits[u32idx] & ~uint32_t(1 << bit);
+    }
+}
+
+// Helper functions to create feature masks
+
+// This can be `std::array<uint32_t,n>` on C++14
+template<size_t n>
+struct FeatureList {
+    uint32_t eles[n];
+    uint32_t &operator[](size_t pos)
+    {
+        return eles[pos];
+    }
+    constexpr const uint32_t &operator[](size_t pos) const
+    {
+        return eles[pos];
+    }
+    inline int nbits() const
+    {
+        int cnt = 0;
+        for (size_t i = 0; i < n; i++)
+            cnt += llvm::countPopulation(eles[i]);
+        return cnt;
+    }
+    inline bool empty() const
+    {
+        for (size_t i = 0; i < n; i++) {
+            if (eles[i]) {
+                return false;
+            }
         }
-        else if (info[3] & (1 << 25)) {
-            // SSE supports only the FZ flag
-            return 0x00008000;
+        return true;
+    }
+};
+
+static inline constexpr uint32_t add_feature_mask_u32(uint32_t mask, uint32_t u32idx)
+{
+    return mask;
+}
+
+template<typename T, typename... Rest>
+static inline constexpr uint32_t add_feature_mask_u32(uint32_t mask, uint32_t u32idx,
+                                                      T bit, Rest... args)
+{
+    return add_feature_mask_u32(mask | ((int(bit) >= 0 && int(bit) / 32 == (int)u32idx) ?
+                                        (1 << (int(bit) % 32)) : 0),
+                                u32idx, args...);
+}
+
+template<typename... Args>
+static inline constexpr uint32_t get_feature_mask_u32(uint32_t u32idx, Args... args)
+{
+    return add_feature_mask_u32(uint32_t(0), u32idx, args...);
+}
+
+template<uint32_t... Is> struct seq{};
+template<uint32_t N, uint32_t... Is>
+struct gen_seq : gen_seq<N-1, N-1, Is...>{};
+template<uint32_t... Is>
+struct gen_seq<0, Is...> : seq<Is...>{};
+
+template<size_t n, uint32_t... I, typename... Args>
+static inline constexpr FeatureList<n>
+_get_feature_mask(seq<I...>, Args... args)
+{
+    return FeatureList<n>{{get_feature_mask_u32(I, args...)...}};
+}
+
+template<size_t n, typename... Args>
+static inline constexpr FeatureList<n> get_feature_masks(Args... args)
+{
+    return _get_feature_mask<n>(gen_seq<n>(), args...);
+}
+
+template<size_t n, uint32_t... I>
+static inline constexpr FeatureList<n>
+_feature_mask_or(seq<I...>, const FeatureList<n> &a, const FeatureList<n> &b)
+{
+    return FeatureList<n>{{(a[I] | b[I])...}};
+}
+
+template<size_t n>
+static inline constexpr FeatureList<n> operator|(const FeatureList<n> &a, const FeatureList<n> &b)
+{
+    return _feature_mask_or<n>(gen_seq<n>(), a, b);
+}
+
+template<size_t n, uint32_t... I>
+static inline constexpr FeatureList<n>
+_feature_mask_and(seq<I...>, const FeatureList<n> &a, const FeatureList<n> &b)
+{
+    return FeatureList<n>{{(a[I] & b[I])...}};
+}
+
+template<size_t n>
+static inline constexpr FeatureList<n> operator&(const FeatureList<n> &a, const FeatureList<n> &b)
+{
+    return _feature_mask_and<n>(gen_seq<n>(), a, b);
+}
+
+template<size_t n, uint32_t... I>
+static inline constexpr FeatureList<n>
+_feature_mask_not(seq<I...>, const FeatureList<n> &a)
+{
+    return FeatureList<n>{{(~a[I])...}};
+}
+
+template<size_t n>
+static inline constexpr FeatureList<n> operator~(const FeatureList<n> &a)
+{
+    return _feature_mask_not<n>(gen_seq<n>(), a);
+}
+
+template<size_t n>
+static inline void mask_features(const FeatureList<n> masks, uint32_t *features)
+{
+    for (size_t i = 0; i < n; i++) {
+        features[i] = features[i] & masks[i];
+    }
+}
+
+// Turn feature list to a string the LLVM accept
+static inline std::string join_feature_strs(const std::vector<std::string> &strs)
+{
+    size_t nstr = strs.size();
+    if (!nstr)
+        return std::string("");
+    std::string str = strs[0];
+    for (size_t i = 1; i < nstr; i++)
+        str += ',' + strs[i];
+    return str;
+}
+
+static inline void append_ext_features(std::string &features, const std::string &ext_features)
+{
+    if (ext_features.empty())
+        return;
+    if (!features.empty())
+        features.push_back(',');
+    features.append(ext_features);
+}
+
+static inline void append_ext_features(std::vector<std::string> &features,
+                                       const std::string &ext_features)
+{
+    if (ext_features.empty())
+        return;
+    const char *start = ext_features.c_str();
+    for (const char *p = start; *p; p++) {
+        if (*p == ',' || *p == '\0') {
+            features.emplace_back(start, p - start);
+            start = p + 1;
         }
     }
-    return 0;
 }
 
-// Cache of information recovered from `cpuid` since executing `cpuid` it at runtime is slow.
-static uint32_t subnormal_flags = get_subnormal_flags();
+/**
+ * Target specific type/constant definitions, always enable.
+ */
+
+struct FeatureName {
+    const char *name;
+    uint32_t bit; // bit index into a `uint32_t` array;
+    uint32_t llvmver; // 0 if it is available on the oldest LLVM version we support
+};
+
+template<typename CPU, size_t n>
+struct CPUSpec {
+    const char *name;
+    CPU cpu;
+    CPU fallback;
+    uint32_t llvmver;
+    FeatureList<n> features;
+};
+
+struct FeatureDep {
+    uint32_t feature;
+    uint32_t dep;
+};
 
-// Returns non-zero if subnormals go to 0; zero otherwise.
-JL_DLLEXPORT int32_t jl_get_zero_subnormals(void)
+// Recursively enable all features that the current feature set depends on.
+template<size_t n>
+static inline void enable_depends(FeatureList<n> &features, const FeatureDep *deps, size_t ndeps)
 {
-    return _mm_getcsr() & subnormal_flags;
+    bool changed = true;
+    while (changed) {
+        changed = false;
+        for (ssize_t i = ndeps - 1; i >= 0; i--) {
+            auto &dep = deps[i];
+            if (!test_nbit(features, dep.feature) || test_nbit(features, dep.dep))
+                continue;
+            set_bit(features, dep.dep, true);
+            changed = true;
+        }
+    }
+}
+
+// Recursively disable all features that the current feature set does not provide.
+template<size_t n>
+static inline void disable_depends(FeatureList<n> &features, const FeatureDep *deps, size_t ndeps)
+{
+    bool changed = true;
+    while (changed) {
+        changed = false;
+        for (ssize_t i = ndeps - 1; i >= 0; i--) {
+            auto &dep = deps[i];
+            if (!test_nbit(features, dep.feature) || test_nbit(features, dep.dep))
+                continue;
+            unset_bits(features, dep.feature);
+            changed = true;
+        }
+    }
+}
+
+template<typename CPU, size_t n>
+static const CPUSpec<CPU,n> *find_cpu(uint32_t cpu, const CPUSpec<CPU,n> *cpus, uint32_t ncpus)
+{
+    for (uint32_t i = 0; i < ncpus; i++) {
+        if (cpu == uint32_t(cpus[i].cpu)) {
+            return &cpus[i];
+        }
+    }
+    return nullptr;
 }
 
-// Return zero on success, non-zero on failure.
-JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
+template<typename CPU, size_t n>
+static const CPUSpec<CPU,n> *find_cpu(const char *name, const CPUSpec<CPU,n> *cpus, uint32_t ncpus)
 {
-    uint32_t flags = subnormal_flags;
-    if (flags) {
-        uint32_t state = _mm_getcsr();
-        if (isZero)
-            state |= flags;
-        else
-            state &= ~flags;
-        _mm_setcsr(state);
+    for (uint32_t i = 0; i < ncpus; i++) {
+        if (strcmp(name, cpus[i].name) == 0) {
+            return &cpus[i];
+        }
+    }
+    return nullptr;
+}
+
+template<typename CPU, size_t n>
+static const char *find_cpu_name(uint32_t cpu, const CPUSpec<CPU,n> *cpus, uint32_t ncpus)
+{
+    if (auto *spec = find_cpu(cpu, cpus, ncpus))
+        return spec->name;
+    return "generic";
+}
+
+template<typename CPU, size_t n>
+static CPU find_cpu_id(const char *name, const CPUSpec<CPU,n> *cpus, uint32_t ncpus,
+                       uint32_t def=0)
+{
+    if (auto *spec = find_cpu(name, cpus, ncpus))
+        return spec->cpu;
+    return static_cast<CPU>(def);
+}
+
+JL_UNUSED static uint32_t find_feature_bit(const FeatureName *features, size_t nfeatures,
+                                           const char *str, size_t len)
+{
+    for (size_t i = 0; i < nfeatures; i++) {
+        auto &feature = features[i];
+        if (strncmp(feature.name, str, len) == 0 && feature.name[len] == 0) {
+            return feature.bit;
+        }
+    }
+    return (uint32_t)-1;
+}
+
+// This is how we save the target identification.
+// CPU name is saved as string instead of binary data like features because
+// 1. CPU ID is less stable (they are not bound to hardware/OS API)
+// 2. We need to support CPU names that are not recognized by us and therefore doesn't have an ID
+// 3. CPU name is trivial to parse
+static inline std::vector<uint8_t> serialize_target_data(const char *name,
+                                                         uint32_t nfeature,
+                                                         const uint32_t *features_en,
+                                                         const uint32_t *features_dis,
+                                                         const char *ext_features)
+{
+    std::vector<uint8_t> res;
+    auto add_data = [&] (const void *data, size_t sz) {
+        size_t old_sz = res.size();
+        res.resize(old_sz + sz);
+        memcpy(&res[old_sz], data, sz);
+    };
+    add_data(&nfeature, 4);
+    add_data(features_en, 4 * nfeature);
+    add_data(features_dis, 4 * nfeature);
+    uint32_t namelen = strlen(name);
+    add_data(&namelen, 4);
+    add_data(name, namelen);
+    uint32_t ext_features_len = strlen(ext_features);
+    add_data(&ext_features_len, 4);
+    add_data(ext_features, ext_features_len);
+    return res;
+}
+
+template<size_t n>
+static inline std::vector<uint8_t> serialize_target_data(const char *name,
+                                                         const FeatureList<n> &features_en,
+                                                         const FeatureList<n> &features_dis,
+                                                         const char *ext_features)
+{
+    return serialize_target_data(name, n, &features_en[0], &features_dis[0], ext_features);
+}
+
+template<size_t n>
+struct TargetData {
+    std::string name;
+    std::string ext_features;
+    struct {
+        FeatureList<n> features;
+        uint32_t flags;
+    } en, dis;
+    int base;
+};
+
+// In addition to the serialized data, the first `uint32_t` gives the number of targets saved
+// and each target has a `uint32_t` flag before the serialized target data.
+template<size_t n>
+static inline std::vector<TargetData<n>> deserialize_target_data(const uint8_t *data)
+{
+    auto load_data = [&] (void *dest, size_t sz) {
+        memcpy(dest, data, sz);
+        data += sz;
+    };
+    auto load_string = [&] () {
+        uint32_t len;
+        load_data(&len, 4);
+        std::string res((const char*)data, len);
+        data += len;
+        return res;
+    };
+    uint32_t ntarget;
+    load_data(&ntarget, 4);
+    std::vector<TargetData<n>> res(ntarget);
+    for (uint32_t i = 0; i < ntarget; i++) {
+        auto &target = res[i];
+        load_data(&target.en.flags, 4);
+        target.dis.flags = 0;
+        // Starting serialized target data
+        uint32_t nfeature;
+        load_data(&nfeature, 4);
+        assert(nfeature == n);
+        load_data(&target.en.features[0], 4 * n);
+        load_data(&target.dis.features[0], 4 * n);
+        target.name = load_string();
+        target.ext_features = load_string();
+        target.base = 0;
+    }
+    return res;
+}
+
+// Try getting clone base argument. Return 1-based index. Return 0 if match failed.
+static inline int get_clone_base(const char *start, const char *end)
+{
+    const char *prefix = "base(";
+    const int prefix_len = strlen(prefix);
+    if (end - start <= prefix_len)
+        return 0;
+    if (memcmp(start, prefix, prefix_len) != 0)
+        return 0;
+    start += prefix_len;
+    if (*start > '9' || *start < '0')
         return 0;
+    char *digit_end;
+    auto idx = strtol(start, &digit_end, 10);
+    if (idx < 0)
+        return 0;
+    if (*digit_end != ')' || digit_end + 1 != end)
+        return 0;
+    return (int)idx + 1;
+}
+
+// Parse cmdline string. This handles `clone_all` and `base` special features.
+// Other feature names will be passed to `feature_cb` for target dependent parsing.
+template<size_t n, typename F>
+static inline std::vector<TargetData<n>>
+parse_cmdline(const char *option, F &&feature_cb)
+{
+    if (!option)
+        option = "native";
+    std::vector<TargetData<n>> res;
+    TargetData<n> arg{};
+    auto reset_arg = [&] {
+        res.push_back(arg);
+        arg.name.clear();
+        arg.ext_features.clear();
+        memset(&arg.en.features[0], 0, 4 * n);
+        memset(&arg.dis.features[0], 0, 4 * n);
+        arg.en.flags = 0;
+        arg.dis.flags = 0;
+    };
+    const char *start = option;
+    for (const char *p = option; ; p++) {
+        switch (*p) {
+        case ',':
+        case ';':
+        case '\0': {
+            bool done = *p == '\0';
+            bool next_target = *p == ';' || done;
+            if (arg.name.empty()) {
+                if (p == start)
+                    jl_error("Invalid target option: empty CPU name");
+                arg.name.append(start, p - start);
+                if (arg.name == "help") {
+                    arg.name = "native";
+                    jl_processor_print_help = true;
+                }
+                start = p + 1;
+                if (next_target)
+                    reset_arg();
+                if (done)
+                    return res;
+                continue;
+            }
+            bool disable = false;
+            const char *full = start;
+            const char *fname = full;
+            start = p + 1;
+            if (*full == '-') {
+                disable = true;
+                fname++;
+            }
+            else if (*full == '+') {
+                fname++;
+            }
+            if (llvm::StringRef(fname, p - fname) == "clone_all") {
+                if (!disable) {
+                    arg.en.flags |= JL_TARGET_CLONE_ALL;
+                    arg.dis.flags &= ~JL_TARGET_CLONE_ALL;
+                }
+                else {
+                    arg.dis.flags |= JL_TARGET_CLONE_ALL;
+                    arg.en.flags &= ~JL_TARGET_CLONE_ALL;
+                }
+            }
+            else if (int base = get_clone_base(fname, p)) {
+                if (disable)
+                    jl_error("Invalid target option: disabled base index.");
+                base -= 1;
+                if (base >= (int)res.size())
+                    jl_error("Invalid target option: base index must refer to a previous target.");
+                if (res[base].dis.flags & JL_TARGET_CLONE_ALL ||
+                    !(res[base].en.flags & JL_TARGET_CLONE_ALL))
+                    jl_error("Invalid target option: base target must be clone_all.");
+                arg.base = base;
+            }
+            else if (llvm::StringRef(fname, p - fname) == "help") {
+                jl_processor_print_help = true;
+            }
+            else {
+                FeatureList<n> &list = disable ? arg.dis.features : arg.en.features;
+                if (!feature_cb(fname, p - fname, list)) {
+                    if (!arg.ext_features.empty())
+                        arg.ext_features += ',';
+                    arg.ext_features += disable ? '-' : '+';
+                    arg.ext_features.append(fname, p - fname);
+                }
+            }
+            if (next_target)
+                reset_arg();
+            if (done) {
+                return res;
+            }
+        }
+            JL_FALLTHROUGH;
+        default:
+            continue;
+        }
+    }
+}
+
+// Cached version of command line parsing
+template<size_t n, typename F>
+static inline std::vector<TargetData<n>> &get_cmdline_targets(F &&feature_cb)
+{
+    static std::vector<TargetData<n>> targets =
+        parse_cmdline<n>(jl_options.cpu_target, std::forward<F>(feature_cb));
+    return targets;
+}
+
+// Load sysimg, use the `callback` for dispatch and perform all relocations
+// for the selected target.
+template<typename F>
+static inline jl_sysimg_fptrs_t parse_sysimg(void *hdl, F &&callback)
+{
+    jl_sysimg_fptrs_t res = {nullptr, 0, nullptr, 0, nullptr, nullptr};
+    // .data base
+    auto data_base = (char*)jl_dlsym(hdl, "jl_sysimg_gvars_base");
+    // .text base
+    res.base = (const char*)jl_dlsym(hdl, "jl_sysimg_fvars_base");
+    auto offsets = ((const int32_t*)jl_dlsym(hdl, "jl_sysimg_fvars_offsets")) + 1;
+    uint32_t nfunc = ((const uint32_t*)offsets)[-1];
+    res.offsets = offsets;
+
+    void *ids = jl_dlsym(hdl, "jl_dispatch_target_ids");
+    uint32_t target_idx = callback(ids);
+
+    auto reloc_slots = ((const int32_t*)jl_dlsym(hdl, "jl_dispatch_reloc_slots")) + 1;
+    auto nreloc = ((const uint32_t*)reloc_slots)[-1];
+    auto clone_idxs = (const uint32_t*)jl_dlsym(hdl, "jl_dispatch_fvars_idxs");
+    auto clone_offsets = (const int32_t*)jl_dlsym(hdl, "jl_dispatch_fvars_offsets");
+    uint32_t tag_len = clone_idxs[0];
+    clone_idxs += 1;
+    assert(tag_len & jl_sysimg_tag_mask);
+    std::vector<const int32_t*> base_offsets = {res.offsets};
+    // Find target
+    for (uint32_t i = 0;i < target_idx;i++) {
+        uint32_t len = jl_sysimg_val_mask & tag_len;
+        if (jl_sysimg_tag_mask & tag_len) {
+            if (i != 0)
+                clone_offsets += nfunc;
+            clone_idxs += len + 1;
+        }
+        else {
+            clone_offsets += len;
+            clone_idxs += len + 2;
+        }
+        tag_len = clone_idxs[-1];
+        base_offsets.push_back(tag_len & jl_sysimg_tag_mask ? clone_offsets : nullptr);
+    }
+
+    bool clone_all = (tag_len & jl_sysimg_tag_mask) != 0;
+    // Fill in return value
+    if (clone_all) {
+        // clone_all
+        if (target_idx != 0) {
+            res.offsets = clone_offsets;
+        }
     }
     else {
-        // Report a failure only if user is trying to enable FTZ/DAZ.
-        return isZero;
+        uint32_t base_idx = clone_idxs[0];
+        assert(base_idx < target_idx);
+        if (target_idx != 0) {
+            res.offsets = base_offsets[base_idx];
+            assert(res.offsets);
+        }
+        clone_idxs++;
+        res.nclones = tag_len;
+        res.clone_offsets = clone_offsets;
+        res.clone_idxs = clone_idxs;
+    }
+    // Do relocation
+    uint32_t reloc_i = 0;
+    uint32_t len = jl_sysimg_val_mask & tag_len;
+    for (uint32_t i = 0; i < len; i++) {
+        uint32_t idx = clone_idxs[i];
+        int32_t offset;
+        if (clone_all) {
+            offset = res.offsets[idx];
+        }
+        else if (idx & jl_sysimg_tag_mask) {
+            idx = idx & jl_sysimg_val_mask;
+            offset = clone_offsets[i];
+        }
+        else {
+            continue;
+        }
+        bool found = false;
+        for (; reloc_i < nreloc; reloc_i++) {
+            auto reloc_idx = ((const uint32_t*)reloc_slots)[reloc_i * 2];
+            if (reloc_idx == idx) {
+                found = true;
+                auto slot = (const void**)(data_base + reloc_slots[reloc_i * 2 + 1]);
+                *slot = offset + res.base;
+            }
+            else if (reloc_idx > idx) {
+                break;
+            }
+        }
+        assert(found && "Cannot find GOT entry for cloned function.");
+        (void)found;
+    }
+
+    return res;
+}
+
+template<typename T>
+static inline void check_cmdline(T &&cmdline, bool imaging)
+{
+    assert(cmdline.size() > 0);
+    // It's unclear what does specifying multiple target when not generating
+    // sysimg means. Make it an error for now.
+    if (!imaging) {
+        if (cmdline.size() > 1) {
+            jl_error("More than one command line CPU targets specified "
+                     "without a `--output-` flag specified");
+        }
+        if (cmdline[0].en.flags & JL_TARGET_CLONE_ALL) {
+            jl_error("\"clone_all\" feature specified "
+                     "without a `--output-` flag specified");
+        }
+    }
+}
+
+struct SysimgMatch {
+    uint32_t best_idx{(uint32_t)-1};
+    int vreg_size{0};
+};
+
+// Find the best match in the sysimg.
+// Select the best one based on the largest vector register and largest compatible feature set.
+template<typename S, typename T, typename F>
+static inline SysimgMatch match_sysimg_targets(S &&sysimg, T &&target, F &&max_vector_size)
+{
+    SysimgMatch match;
+    bool match_name = false;
+    int feature_size = 0;
+    for (uint32_t i = 0; i < sysimg.size(); i++) {
+        auto &imgt = sysimg[i];
+        if (!(imgt.en.features & target.dis.features).empty()) {
+            // Check sysimg enabled features against runtime disabled features
+            // This is valid (and all what we can do)
+            // even if one or both of the targets are unknown.
+            continue;
+        }
+        if (imgt.name == target.name) {
+            if (!match_name) {
+                match_name = true;
+                match.vreg_size = 0;
+                feature_size = 0;
+            }
+        }
+        else if (match_name) {
+            continue;
+        }
+        int new_vsz = max_vector_size(imgt.en.features);
+        if (match.vreg_size > new_vsz)
+            continue;
+        int new_feature_size = imgt.en.features.nbits();
+        if (match.vreg_size < new_vsz) {
+            match.best_idx = i;
+            match.vreg_size = new_vsz;
+            feature_size = new_feature_size;
+            continue;
+        }
+        if (new_feature_size < feature_size)
+            continue;
+        match.best_idx = i;
+        feature_size = new_feature_size;
+    }
+    if (match.best_idx == (uint32_t)-1)
+        jl_error("Unable to find compatible target in system image.");
+    return match;
+}
+
+// Debug helper
+
+template<typename CPU, size_t n>
+static inline void dump_cpu_spec(uint32_t cpu, const FeatureList<n> &features,
+                                 const FeatureName *feature_names, uint32_t nfeature_names,
+                                 const CPUSpec<CPU,n> *cpus, uint32_t ncpus)
+{
+    bool cpu_found = false;
+    for (uint32_t i = 0;i < ncpus;i++) {
+        if (cpu == uint32_t(cpus[i].cpu)) {
+            cpu_found = true;
+            jl_safe_printf("CPU: %s\n", cpus[i].name);
+            break;
+        }
     }
+    if (!cpu_found)
+        jl_safe_printf("CPU: generic\n");
+    jl_safe_printf("Features:");
+    bool first = true;
+    for (uint32_t i = 0;i < nfeature_names;i++) {
+        if (test_nbit(&features[0], feature_names[i].bit)) {
+            if (first) {
+                jl_safe_printf(" %s", feature_names[i].name);
+                first = false;
+            }
+            else {
+                jl_safe_printf(", %s", feature_names[i].name);
+            }
+        }
+    }
+    jl_safe_printf("\n");
+}
+
 }
 
+#if defined(_CPU_X86_) || defined(_CPU_X86_64_)
+
+#include "processor_x86.cpp"
+
 #elif defined(_CPU_AARCH64_)
 
+// TODO
+JL_DLLEXPORT jl_value_t *jl_get_cpu_name(void)
+{
+    return jl_cstr_to_string(jl_get_cpu_name_llvm().c_str());
+}
+
 // FZ, bit [24]
 static const uint32_t fpcr_fz_mask = 1 << 24;
 
@@ -123,12 +824,12 @@ static inline void set_fpcr_aarch64(uint32_t fpcr)
     asm volatile("msr fpcr, %0" :: "r"(fpcr));
 }
 
-JL_DLLEXPORT int32_t jl_get_zero_subnormals(void)
+extern "C" JL_DLLEXPORT int32_t jl_get_zero_subnormals(void)
 {
     return (get_fpcr_aarch64() & fpcr_fz_mask) != 0;
 }
 
-JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
+extern "C" JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
 {
     uint32_t fpcr = get_fpcr_aarch64();
     fpcr = isZero ? (fpcr | fpcr_fz_mask) : (fpcr & ~fpcr_fz_mask);
@@ -138,16 +839,30 @@ JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
 
 #else
 
-JL_DLLEXPORT int32_t jl_get_zero_subnormals(void)
+JL_DLLEXPORT jl_value_t *jl_get_cpu_name(void)
+{
+    return jl_cstr_to_string(jl_get_cpu_name_llvm().c_str());
+}
+
+JL_DLLEXPORT void jl_dump_host_cpu(void)
+{
+    jl_safe_printf("CPU: generic\n");
+    jl_safe_printf("Features:\n");
+}
+
+extern "C" int jl_test_cpu_feature(jl_cpu_feature_t feature)
 {
     return 0;
 }
 
-JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
+extern "C" JL_DLLEXPORT int32_t jl_get_zero_subnormals(void)
+{
+    return 0;
+}
+
+extern "C" JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
 {
     return isZero;
 }
 
 #endif
-
-}
diff --git a/src/processor.h b/src/processor.h
new file mode 100644
index 0000000000..7b43aaca8a
--- /dev/null
+++ b/src/processor.h
@@ -0,0 +1,200 @@
+// This file is a part of Julia. License is MIT: https://julialang.org/license
+
+#include "support/dtypes.h"
+
+#include "julia.h"
+
+#include <stddef.h>
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/**
+ * Related sysimg exported symbols
+ *
+ * In the following text function refer to an abstract identity.
+ * It corresponds to a `Function` that we emit in the codegen and there might be multiple copy
+ * of it in the system image. Only one of those copy will be used in a given session.
+ * Function pointers refer to a real piece of code in the system image.
+ * Each function might have multiple function pointers in the system image
+ * and each function pointer will correspond to only one function.
+ *
+ * # Global function and base pointers
+ * `jl_sysimg_gvars_base`:
+ *     The address of this symbol is the base data pointer
+ *     (all other data pointers are stored as offsets to this address)
+ * `jl_sysimg_fvars_base`:
+ *     The address of this symbol is the base function pointer
+ *     (all other function pointers are stored as offsets to this address)
+ * `jl_sysimg_fvars_offsets`: [static data]
+ *     The array of function pointer offsets (`int32_t`) from the base pointer.
+ *     This includes all julia functions in sysimg as well as all other functions that are cloned.
+ *     The default function pointer is used if the function is cloned.
+ *     The first element is the size of the array, which should **NOT** be used as the number
+ *     of julia functions in the sysimg.
+ *     Each entry in this array uniquely identifies a function which we are interested in
+ *     (the function may have multiple function pointers corresponding to different versions).
+ *     In other sysimg info, all information of functions are stored as function index which are
+ *     `uint32_t` index in this array.
+ *
+ * # Target data and dispatch slots (Only needed by runtime during loading)
+ * `jl_dispatch_target_ids`: [static data] serialize target data.
+ *     This contains the number of targets which is needed to decode `jl_dispatch_fvars_idxs`
+ *     in additional to the name and feature set of each target.
+ * `jl_dispatch_reloc_slots`: [static data] location and index of relocation slots.
+ *     Stored as pairs of function indices and `int32_t` offsets from `jl_sysimg_gvars_base`.
+ *     The first element is an `uint32_t` giving the number of relocations.
+ *     This is needed for functions whose address is used in a way that requires dispatch.
+ *     We currently only support one type of relocation (i.e. absolute pointer) which is enough
+ *     for all use in functions as well as global GOT slot (for "PLT" callback).
+ *     Note that not all functions being cloned are assigned a slot.
+ *     This array is sorted by the function indices.
+ *     There can be more than one slot per-function,
+ *     i.e. there can be duplicated function indices.
+ *
+ * # Target functions
+ * `jl_dispatch_fvars_idxs`: [static data] Target specific functions indices.
+ *     For each target, this includes a tagged `uint32_t` length, an optional `uint32_t` index
+ *     of the base target followed by an array of tagged function indices.
+ *     The base target index is required to be smaller than the index of the current target
+ *     and must be the default (`0`) or a `clone_all` target.
+ *     If it's not `0`, the function pointer array for the `clone_all` target will be used as
+ *     the base function pointer offsets instead.
+ *     The tag bits for both the length and the indices are the top bit.
+ *     A tagged length indicates that all of the functions are cloned and the indices follows
+ *     are the ones that requires relocation. The base target index is omitted in this case.
+ *     Otherwise, the length is the total number of functions that we are interested in
+ *     for this target, which includes all cloned julia functions and
+ *     all other cloned functions that requires relocation.
+ *     A tagged index means that the function pointer should be filled into the GOT slots
+ *     identified by `jl_dispatch_reloc_slots`. There could be more than one slot per function.
+ *     (Note that a tagged index could corresponds to a functions pointer that's the same as
+ *     the base one since this is the only way we currently represent relocations.)
+ *     A tagged length implicitly tags all the indices and the indices will not have the tag bit
+ *     set. The lengths in this variable is needed to decode `jl_dispatch_fvars_offsets`.
+ * `jl_dispatch_fvars_offsets`: [static data] Target specific function pointer offsets.
+ *     This contains all the cloned functions that we are interested and it needs to be decoded
+ *     and used along with `jl_dispatch_fvars_idxs`.
+ *     For the default target, there's no entries in this variable, if there's any relocations
+ *     needed for the default target, the function pointers are taken from the global offset
+ *     arrays directly.
+ *     For a `clone_all` target (i.e. with the length in `jl_dispatch_fvars_idxs` tagged), this
+ *     variable contains an offset array the same length as the global one. Only the indices
+ *     appeared in `jl_dispatch_fvars_idxs` needs relocation and the dispatch code should return
+ *     this array as the original/base function offsets.
+ *     For other targets, this variable contains an offset array with the length defined in
+ *     `jl_dispatch_fvars_idxs`. Tagged indices needs relocations.
+ */
+
+enum {
+    JL_TARGET_VEC_CALL = 1 << 0,
+    // Clone all functions
+    JL_TARGET_CLONE_ALL = 1 << 1,
+    // Clone when there's scalar math operations that can benefit from target specific
+    // optimizations. This includes `muladd`, `fma`, `fast`/`contract` flags.
+    JL_TARGET_CLONE_MATH = 1 << 2,
+    // Clone when the function has a loop
+    JL_TARGET_CLONE_LOOP = 1 << 3,
+    // Clone when the function uses any vectors
+    // When this is specified, the cloning pass should also record if any of the cloned functions
+    // used this in any function call (including the signature of the function itself)
+    JL_TARGET_CLONE_SIMD = 1 << 4,
+    // The CPU name is unknown
+    JL_TARGET_UNKNOWN_NAME = 1 << 5,
+};
+
+#define JL_FEATURE_DEF_NAME(name, bit, llvmver, str) JL_FEATURE_DEF(name, bit, llvmver)
+typedef enum {
+#define JL_FEATURE_DEF(name, bit, llvmver) JL_X86_##name = bit,
+#include "features_x86.h"
+#undef JL_FEATURE_DEF
+} jl_cpu_feature_t;
+#undef JL_FEATURE_DEF_NAME
+
+int jl_test_cpu_feature(jl_cpu_feature_t feature);
+
+static const uint32_t jl_sysimg_tag_mask = 0x80000000u;
+static const uint32_t jl_sysimg_val_mask = ~((uint32_t)0x80000000u);
+
+typedef struct {
+    // base function pointer
+    const char *base;
+    // number of functions
+    uint32_t noffsets;
+    // function pointer offsets
+    const int32_t *offsets;
+
+    // Following fields contains the information about the selected target.
+    // All of these fields are 0 if the selected targets have all the functions cloned.
+    // Instead the offsets are stored in `noffsets` and `offsets`.
+
+    // number of cloned functions
+    uint32_t nclones;
+    // function pointer offsets of cloned functions
+    const int32_t *clone_offsets;
+    // sorted indices of the cloned functions (including the tag bit)
+    const uint32_t *clone_idxs;
+} jl_sysimg_fptrs_t;
+
+/**
+ * Initialize the processor dispatch system with sysimg `hdl` (also initialize the sysimg itself).
+ * The dispatch system will find the best implementation to be used in this session.
+ * The decision will be based on the host CPU and features as well as the `cpu_target`
+ * option. This must be called before initializing JIT and should only be called once.
+ * An error will be raised if this is called more than once or none of the implementation
+ * supports the current system.
+ *
+ * Return the data about the function pointers selected.
+ */
+jl_sysimg_fptrs_t jl_init_processor_sysimg(void *hdl);
+
+// Return the name of the host CPU as a julia string.
+JL_DLLEXPORT jl_value_t *jl_get_cpu_name(void);
+// Dump the name and feature set of the host CPU
+// For debugging only
+JL_DLLEXPORT void jl_dump_host_cpu(void);
+
+#ifdef __cplusplus
+}
+
+#include <utility>
+#include <string>
+#include <vector>
+
+extern bool jl_processor_print_help;
+
+/**
+ * Returns the CPU name and feature string to be used by LLVM JIT.
+ *
+ * If the detected/specified CPU name is not available on the LLVM version specified,
+ * a fallback CPU name will be used. Unsupported features will be ignored.
+ */
+std::pair<std::string,std::vector<std::string>> jl_get_llvm_target(bool imaging, uint32_t &flags);
+
+/**
+ * Returns the CPU name and feature string to be used by LLVM disassembler.
+ *
+ * This will return a generic CPU name and a full feature string.
+ */
+const std::pair<std::string,std::string> &jl_get_llvm_disasm_target(void);
+
+struct jl_target_spec_t {
+    // LLVM target name
+    std::string cpu_name;
+    // LLVM feature string
+    std::string cpu_features;
+    // serialized identification data
+    std::vector<uint8_t> data;
+    // Clone condition.
+    uint32_t flags;
+    // Base target index.
+    int base;
+};
+/**
+ * Return the list of targets to clone
+ */
+std::vector<jl_target_spec_t> jl_get_llvm_clone_targets(void);
+std::string jl_get_cpu_name_llvm(void);
+#endif
diff --git a/src/processor_x86.cpp b/src/processor_x86.cpp
new file mode 100644
index 0000000000..c2ace34021
--- /dev/null
+++ b/src/processor_x86.cpp
@@ -0,0 +1,948 @@
+// This file is a part of Julia. License is MIT: https://julialang.org/license
+
+// X86 specific processor detection and dispatch
+
+// CPUID
+
+extern "C" JL_DLLEXPORT void jl_cpuid(int32_t CPUInfo[4], int32_t InfoType)
+{
+#if defined _MSC_VER
+    __cpuid(CPUInfo, InfoType);
+#else
+    asm volatile (
+#if defined(__i386__) && defined(__PIC__)
+        "xchg %%ebx, %%esi;"
+        "cpuid;"
+        "xchg %%esi, %%ebx;" :
+        "=S" (CPUInfo[1]),
+#else
+        "cpuid" :
+        "=b" (CPUInfo[1]),
+#endif
+        "=a" (CPUInfo[0]),
+        "=c" (CPUInfo[2]),
+        "=d" (CPUInfo[3]) :
+        "a" (InfoType)
+        );
+#endif
+}
+
+extern "C" JL_DLLEXPORT void jl_cpuidex(int32_t CPUInfo[4], int32_t InfoType, int32_t subInfoType)
+{
+#if defined _MSC_VER
+    __cpuidex(CPUInfo, InfoType, subInfoType);
+#else
+    asm volatile (
+#if defined(__i386__) && defined(__PIC__)
+        "xchg %%ebx, %%esi;"
+        "cpuid;"
+        "xchg %%esi, %%ebx;" :
+        "=S" (CPUInfo[1]),
+#else
+        "cpuid" :
+        "=b" (CPUInfo[1]),
+#endif
+        "=a" (CPUInfo[0]),
+        "=c" (CPUInfo[2]),
+        "=d" (CPUInfo[3]) :
+        "a" (InfoType),
+        "c" (subInfoType)
+        );
+#endif
+}
+
+namespace X86 {
+
+enum class CPU : uint32_t {
+    generic = 0,
+    intel_nocona,
+    intel_prescott,
+    intel_atom_bonnell,
+    intel_atom_silvermont,
+    intel_atom_goldmont,
+    intel_core2,
+    intel_core2_penryn,
+    intel_yonah,
+    intel_corei7_nehalem,
+    intel_corei7_westmere,
+    intel_corei7_sandybridge,
+    intel_corei7_ivybridge,
+    intel_corei7_haswell,
+    intel_corei7_broadwell,
+    intel_corei7_skylake,
+    intel_corei7_skylake_avx512,
+    intel_corei7_cannonlake,
+    intel_knights_landing,
+
+    amd_fam10h,
+    amd_athlon_fx,
+    amd_athlon_64,
+    amd_athlon_64_sse3,
+    amd_bdver1,
+    amd_bdver2,
+    amd_bdver3,
+    amd_bdver4,
+    amd_btver1,
+    amd_btver2,
+    amd_k8,
+    amd_k8_sse3,
+    amd_opteron,
+    amd_opteron_sse3,
+    amd_barcelona,
+    amd_znver1,
+};
+
+static constexpr size_t feature_sz = 9;
+static constexpr FeatureName feature_names[] = {
+#define JL_FEATURE_DEF(name, bit, llvmver) {#name, bit, llvmver},
+#define JL_FEATURE_DEF_NAME(name, bit, llvmver, str) {str, bit, llvmver},
+#include "features_x86.h"
+#undef JL_FEATURE_DEF
+#undef JL_FEATURE_DEF_NAME
+};
+static constexpr uint32_t nfeature_names = sizeof(feature_names) / sizeof(FeatureName);
+
+template<typename... Args>
+static inline constexpr FeatureList<feature_sz> get_feature_masks(Args... args)
+{
+    return ::get_feature_masks<feature_sz>(args...);
+}
+
+#define JL_FEATURE_DEF_NAME(name, bit, llvmver, str) JL_FEATURE_DEF(name, bit, llvmver)
+static constexpr auto feature_masks = get_feature_masks(
+#define JL_FEATURE_DEF(name, bit, llvmver) bit,
+#include "features_x86.h"
+#undef JL_FEATURE_DEF
+    -1);
+
+namespace Feature {
+enum : uint32_t {
+#define JL_FEATURE_DEF(name, bit, llvmver) name = bit,
+#include "features_x86.h"
+#undef JL_FEATURE_DEF
+};
+#undef JL_FEATURE_DEF_NAME
+static constexpr FeatureDep deps[] = {
+    {ssse3, sse3},
+    {fma, avx},
+    {sse41, ssse3},
+    {sse42, sse41},
+    {avx, sse42},
+    {f16c, avx},
+    {avx2, avx},
+    {avx512f, avx2},
+    {avx512dq, avx512f},
+    {avx512ifma, avx512f},
+    {avx512pf, avx512f},
+    {avx512er, avx512f},
+    {avx512cd, avx512f},
+    {avx512bw, avx512f},
+    {avx512vl, avx512f},
+    {avx512vbmi, avx512bw},
+    {avx512vpopcntdq, avx512f},
+    {sse4a, sse3},
+    {xop, fma4},
+    {fma4, avx},
+    {fma4, sse4a}
+};
+
+constexpr auto generic = get_feature_masks();
+#ifdef _CPU_X86_
+constexpr auto sahf_feature_mask = get_feature_masks();
+#else
+constexpr auto sahf_feature_mask = get_feature_masks(sahf);
+#endif
+constexpr auto bonnell = get_feature_masks(sse3, ssse3, cx16, movbe) | sahf_feature_mask;
+constexpr auto silvermont = bonnell | get_feature_masks(sse41, sse42, popcnt,
+                                                        pclmul, aes, prfchw);
+constexpr auto goldmont = silvermont | get_feature_masks(mpx, sha, rdrnd, rdseed, xsave,
+                                                         xsaveopt, xsavec, xsaves, clflushopt);
+constexpr auto yonah = get_feature_masks(sse3);
+constexpr auto prescott = yonah;
+constexpr auto core2 = get_feature_masks(sse3, ssse3, cx16) | sahf_feature_mask;
+constexpr auto nocona = get_feature_masks(sse3, cx16);
+constexpr auto penryn = nocona | get_feature_masks(ssse3, sse41) | sahf_feature_mask;
+constexpr auto nehalem = penryn | get_feature_masks(sse42, popcnt);
+constexpr auto westmere = nehalem | get_feature_masks(aes, pclmul);
+constexpr auto sandybridge = westmere | get_feature_masks(avx, xsave, xsaveopt);
+constexpr auto ivybridge = sandybridge | get_feature_masks(rdrnd, f16c, fsgsbase);
+constexpr auto haswell = ivybridge | get_feature_masks(avx2, bmi, bmi2, fma, lzcnt, movbe);
+constexpr auto broadwell = haswell | get_feature_masks(adx, rdseed, prfchw);
+constexpr auto skylake = broadwell | get_feature_masks(mpx, rtm, xsavec, xsaves,
+                                                       clflushopt); // ignore sgx; hle
+constexpr auto knl = broadwell | get_feature_masks(avx512f, avx512er, avx512cd, avx512pf,
+                                                   prefetchwt1);
+constexpr auto skx = skylake | get_feature_masks(avx512f, avx512cd, avx512dq, avx512bw, avx512vl,
+                                                 pku, clwb);
+constexpr auto cannonlake = skx | get_feature_masks(avx512vbmi, avx512ifma, sha);
+
+constexpr auto k8_sse3 = get_feature_masks(sse3, cx16);
+constexpr auto amdfam10 = k8_sse3 | get_feature_masks(sse4a, lzcnt, popcnt) | sahf_feature_mask;
+
+constexpr auto btver1 = amdfam10 | get_feature_masks(ssse3, prfchw);
+constexpr auto btver2 = btver1 | get_feature_masks(sse41, sse42, avx, aes, pclmul, bmi, f16c,
+                                                   movbe, xsave, xsaveopt);
+
+constexpr auto bdver1 = amdfam10 | get_feature_masks(xop, fma4, avx, ssse3, sse41, sse42, aes,
+                                                     prfchw, pclmul, xsave, lwp);
+constexpr auto bdver2 = bdver1 | get_feature_masks(f16c, bmi, tbm, fma);
+constexpr auto bdver3 = bdver2 | get_feature_masks(xsaveopt, fsgsbase);
+constexpr auto bdver4 = bdver3 | get_feature_masks(avx2, bmi2, mwaitx);
+
+constexpr auto znver1 = haswell | get_feature_masks(adx, clflushopt, clzero, mwaitx, prfchw,
+                                                    rdseed, sha, sse4a, xsavec, xsaves);
+
+}
+
+static constexpr CPUSpec<CPU, feature_sz> cpus[] = {
+    {"generic", CPU::generic, CPU::generic, 0, Feature::generic},
+    {"bonnell", CPU::intel_atom_bonnell, CPU::generic, 0, Feature::bonnell},
+    {"silvermont", CPU::intel_atom_silvermont, CPU::generic, 0, Feature::silvermont},
+    {"goldmont", CPU::intel_atom_goldmont, CPU::generic, 50000, Feature::goldmont},
+    {"core2", CPU::intel_core2, CPU::generic, 0, Feature::core2},
+    {"yonah", CPU::intel_yonah, CPU::generic, 0, Feature::yonah},
+    {"prescott", CPU::intel_prescott, CPU::generic, 0, Feature::prescott},
+    {"nocona", CPU::intel_nocona, CPU::generic, 0, Feature::nocona},
+    {"penryn", CPU::intel_core2_penryn, CPU::generic, 0, Feature::penryn},
+    {"nehalem", CPU::intel_corei7_nehalem, CPU::generic, 0, Feature::nehalem},
+    {"westmere", CPU::intel_corei7_westmere, CPU::generic, 0, Feature::westmere},
+    {"sandybridge", CPU::intel_corei7_sandybridge, CPU::generic, 0, Feature::sandybridge},
+    {"ivybridge", CPU::intel_corei7_ivybridge, CPU::generic, 0, Feature::ivybridge},
+    {"haswell", CPU::intel_corei7_haswell, CPU::generic, 0, Feature::haswell},
+    {"broadwell", CPU::intel_corei7_broadwell, CPU::generic, 0, Feature::broadwell},
+    {"skylake", CPU::intel_corei7_skylake, CPU::generic, 0, Feature::skylake},
+    {"knl", CPU::intel_knights_landing, CPU::generic, 0, Feature::knl},
+    {"skylake-avx512", CPU::intel_corei7_skylake_avx512, CPU::generic, 0, Feature::skx},
+    {"cannonlake", CPU::intel_corei7_cannonlake, CPU::intel_corei7_skylake_avx512, 40000,
+     Feature::cannonlake},
+
+    {"athlon64", CPU::amd_athlon_64, CPU::generic, 0, Feature::generic},
+    {"athlon-fx", CPU::amd_athlon_fx, CPU::generic, 0, Feature::generic},
+    {"k8", CPU::amd_k8, CPU::generic, 0, Feature::generic},
+    {"opteron", CPU::amd_opteron, CPU::generic, 0, Feature::generic},
+
+    {"athlon64-sse3", CPU::amd_athlon_64_sse3, CPU::generic, 0, Feature::k8_sse3},
+    {"k8-sse3", CPU::amd_k8_sse3, CPU::generic, 0, Feature::k8_sse3},
+    {"opteron-sse3", CPU::amd_opteron_sse3, CPU::generic, 0, Feature::k8_sse3},
+
+    {"amdfam10", CPU::amd_fam10h, CPU::generic, 0, Feature::amdfam10},
+    {"barcelona", CPU::amd_barcelona, CPU::generic, 0, Feature::amdfam10},
+
+    {"btver1", CPU::amd_btver1, CPU::generic, 0, Feature::btver1},
+    {"btver2", CPU::amd_btver2, CPU::generic, 0, Feature::btver2},
+
+    {"bdver1", CPU::amd_bdver1, CPU::generic, 0, Feature::bdver1},
+    {"bdver2", CPU::amd_bdver2, CPU::generic, 0, Feature::bdver2},
+    {"bdver3", CPU::amd_bdver3, CPU::generic, 0, Feature::bdver3},
+    {"bdver4", CPU::amd_bdver4, CPU::generic, 0, Feature::bdver4},
+
+    {"znver1", CPU::amd_znver1, CPU::generic, 0, Feature::znver1},
+};
+static constexpr size_t ncpu_names = sizeof(cpus) / sizeof(cpus[0]);
+
+// For CPU model and feature detection on X86
+
+const int SIG_INTEL = 0x756e6547; // Genu
+const int SIG_AMD = 0x68747541; // Auth
+
+static uint64_t get_xcr0(void)
+{
+#if defined _MSC_VER
+    return _xgetbv(_XCR_XFEATURE_ENABLED_MASK);
+#else
+    uint32_t eax, edx;
+    asm volatile ("xgetbv" : "=a" (eax), "=d" (edx) : "c" (0));
+    return (uint64_t(edx) << 32) | eax;
+#endif
+}
+
+static CPU get_intel_processor_name(uint32_t family, uint32_t model, uint32_t brand_id,
+                                    const uint32_t *features)
+{
+    if (brand_id != 0)
+        return CPU::generic;
+    switch (family) {
+    case 3:
+    case 4:
+    case 5:
+        return CPU::generic;
+    case 6:
+        switch (model) {
+        case 0x01: // Pentium Pro processor
+        case 0x03: // Intel Pentium II OverDrive processor, Pentium II processor, model 03
+        case 0x05: // Pentium II processor, model 05, Pentium II Xeon processor,
+            // model 05, and Intel Celeron processor, model 05
+        case 0x06: // Celeron processor, model 06
+        case 0x07: // Pentium III processor, model 07, and Pentium III Xeon processor, model 07
+        case 0x08: // Pentium III processor, model 08, Pentium III Xeon processor,
+            // model 08, and Celeron processor, model 08
+        case 0x0a: // Pentium III Xeon processor, model 0Ah
+        case 0x0b: // Pentium III processor, model 0Bh
+        case 0x09: // Intel Pentium M processor, Intel Celeron M processor model 09.
+        case 0x0d: // Intel Pentium M processor, Intel Celeron M processor, model
+            // 0Dh. All processors are manufactured using the 90 nm process.
+        case 0x15: // Intel EP80579 Integrated Processor and Intel EP80579
+            // Integrated Processor with Intel QuickAssist Technology
+            return CPU::generic;
+        case 0x0e: // Intel Core Duo processor, Intel Core Solo processor, model
+            // 0Eh. All processors are manufactured using the 65 nm process.
+            return CPU::intel_yonah;
+        case 0x0f: // Intel Core 2 Duo processor, Intel Core 2 Duo mobile
+            // processor, Intel Core 2 Quad processor, Intel Core 2 Quad
+            // mobile processor, Intel Core 2 Extreme processor, Intel
+            // Pentium Dual-Core processor, Intel Xeon processor, model
+            // 0Fh. All processors are manufactured using the 65 nm process.
+        case 0x16: // Intel Celeron processor model 16h. All processors are
+            // manufactured using the 65 nm process
+            return CPU::intel_core2;
+        case 0x17: // Intel Core 2 Extreme processor, Intel Xeon processor, model
+            // 17h. All processors are manufactured using the 45 nm process.
+            //
+            // 45nm: Penryn , Wolfdale, Yorkfield (XE)
+        case 0x1d: // Intel Xeon processor MP. All processors are manufactured using
+            // the 45 nm process.
+            return CPU::intel_core2_penryn;
+        case 0x1a: // Intel Core i7 processor and Intel Xeon processor. All
+            // processors are manufactured using the 45 nm process.
+        case 0x1e: // Intel(R) Core(TM) i7 CPU         870  @ 2.93GHz.
+            // As found in a Summer 2010 model iMac.
+        case 0x1f:
+        case 0x2e: // Nehalem EX
+            return CPU::intel_corei7_nehalem;
+        case 0x25: // Intel Core i7, laptop version.
+        case 0x2c: // Intel Core i7 processor and Intel Xeon processor. All
+            // processors are manufactured using the 32 nm process.
+        case 0x2f: // Westmere EX
+            return CPU::intel_corei7_westmere;
+        case 0x2a: // Intel Core i7 processor. All processors are manufactured
+            // using the 32 nm process.
+        case 0x2d:
+            return CPU::intel_corei7_sandybridge;
+        case 0x3a:
+        case 0x3e: // Ivy Bridge EP
+            return CPU::intel_corei7_ivybridge;
+
+            // Haswell:
+        case 0x3c:
+        case 0x3f:
+        case 0x45:
+        case 0x46:
+            return CPU::intel_corei7_haswell;
+
+            // Broadwell:
+        case 0x3d:
+        case 0x47:
+        case 0x4f:
+        case 0x56:
+            return CPU::intel_corei7_broadwell;
+
+            // Skylake:
+        case 0x4e: // Skylake mobile
+        case 0x5e: // Skylake desktop
+        case 0x8e: // Kaby Lake mobile
+        case 0x9e: // Kaby Lake desktop
+            return CPU::intel_corei7_skylake;
+
+            // Skylake Xeon:
+        case 0x55:
+            return CPU::intel_corei7_skylake;
+
+        case 0x1c: // Most 45 nm Intel Atom processors
+        case 0x26: // 45 nm Atom Lincroft
+        case 0x27: // 32 nm Atom Medfield
+        case 0x35: // 32 nm Atom Midview
+        case 0x36: // 32 nm Atom Midview
+            return CPU::intel_atom_bonnell;
+
+            // Atom Silvermont codes from the Intel software optimization guide.
+        case 0x37:
+        case 0x4a:
+        case 0x4d:
+        case 0x5a:
+        case 0x5d:
+        case 0x4c: // really airmont
+            return CPU::intel_atom_silvermont;
+
+            // Goldmont:
+        case 0x5c:
+        case 0x5f:
+            return CPU::intel_atom_goldmont;
+
+        case 0x57:
+            return CPU::intel_knights_landing;
+
+        default:
+            return CPU::generic;
+        }
+        break;
+    case 15: {
+        switch (model) {
+        case 0: // Pentium 4 processor, Intel Xeon processor. All processors are
+            // model 00h and manufactured using the 0.18 micron process.
+        case 1: // Pentium 4 processor, Intel Xeon processor, Intel Xeon
+            // processor MP, and Intel Celeron processor. All processors are
+            // model 01h and manufactured using the 0.18 micron process.
+        case 2: // Pentium 4 processor, Mobile Intel Pentium 4 processor - M,
+            // Intel Xeon processor, Intel Xeon processor MP, Intel Celeron
+            // processor, and Mobile Intel Celeron processor. All processors
+            // are model 02h and manufactured using the 0.13 micron process.
+        default:
+            return CPU::generic;
+
+        case 3: // Pentium 4 processor, Intel Xeon processor, Intel Celeron D
+            // processor. All processors are model 03h and manufactured using
+            // the 90 nm process.
+        case 4: // Pentium 4 processor, Pentium 4 processor Extreme Edition,
+            // Pentium D processor, Intel Xeon processor, Intel Xeon
+            // processor MP, Intel Celeron D processor. All processors are
+            // model 04h and manufactured using the 90 nm process.
+        case 6: // Pentium 4 processor, Pentium D processor, Pentium processor
+            // Extreme Edition, Intel Xeon processor, Intel Xeon processor
+            // MP, Intel Celeron D processor. All processors are model 06h
+            // and manufactured using the 65 nm process.
+#ifdef _CPU_X86_64_
+            return CPU::intel_nocona;
+#else
+            return CPU::intel_prescott;
+#endif
+        }
+    }
+    default:
+        break; /*"generic"*/
+    }
+    return CPU::generic;
+}
+
+static CPU get_amd_processor_name(uint32_t family, uint32_t model, const uint32_t *features)
+{
+    switch (family) {
+    case 4:
+    case 5:
+    case 6:
+    default:
+        return CPU::generic;
+    case 15:
+        if (test_nbit(features, Feature::sse3))
+            return CPU::amd_k8_sse3;
+        switch (model) {
+        case 1:
+            return CPU::amd_opteron;
+        case 5:
+            return CPU::amd_athlon_fx;
+        default:
+            return CPU::amd_athlon_64;
+        }
+    case 16:
+        switch (model) {
+        case 2:
+            return CPU::amd_barcelona;
+        case 4:
+        case 8:
+        default:
+            return CPU::amd_fam10h;
+        }
+    case 20:
+        return CPU::amd_btver1;
+    case 21:
+        if (!test_nbit(features, Feature::avx))
+            return CPU::amd_btver1;
+        if (model >= 0x50 && model <= 0x6f)
+            return CPU::amd_bdver4;
+        if (model >= 0x30 && model <= 0x3f)
+            return CPU::amd_bdver3;
+        if (model >= 0x10 && model <= 0x1f)
+            return CPU::amd_bdver2;
+        if (model <= 0x0f)
+            return CPU::amd_bdver1;
+        return CPU::amd_btver1; // fallback
+    case 22:
+        if (!test_nbit(features, Feature::avx))
+            return CPU::amd_btver1;
+        return CPU::amd_btver2;
+    case 23:
+        if (test_nbit(features, Feature::adx))
+            return CPU::amd_znver1;
+        return CPU::amd_btver1;
+    }
+}
+
+template<typename T>
+static inline void features_disable_avx512(T &features)
+{
+    using namespace Feature;
+    unset_bits(features, avx512f, avx512dq, avx512ifma, avx512pf, avx512er, avx512cd,
+               avx512bw, avx512vl, avx512vbmi);
+}
+
+template<typename T>
+static inline void features_disable_avx(T &features)
+{
+    using namespace Feature;
+    unset_bits(features, avx, Feature::fma, f16c, xsave, avx2, xop, fma4,
+               xsaveopt, xsavec, xsaves);
+}
+
+static inline const std::pair<uint32_t,FeatureList<feature_sz>> &get_host_cpu()
+{
+    static const auto host_cpu = [] () NOINLINE {
+        FeatureList<feature_sz> features = {};
+
+        int32_t info0[4];
+        jl_cpuid(info0, 0);
+        uint32_t maxleaf = info0[0];
+        if (maxleaf < 1)
+            return std::make_pair(uint32_t(CPU::generic), features);
+        int32_t info1[4];
+        jl_cpuid(info1, 1);
+
+        auto vendor = info0[1];
+        auto brand_id = info1[1] & 0xff;
+
+        auto family = (info1[0] >> 8) & 0xf; // Bits 8 - 11
+        auto model = (info1[0] >> 4) & 0xf;  // Bits 4 - 7
+        if (family == 6 || family == 0xf) {
+            if (family == 0xf)
+                // Examine extended family ID if family ID is F.
+                family += (info1[0] >> 20) & 0xff; // Bits 20 - 27
+            // Examine extended model ID if family ID is 6 or F.
+            model += ((info1[0] >> 16) & 0xf) << 4; // Bits 16 - 19
+        }
+
+        // Fill in the features
+        features[0] = info1[2];
+        features[1] = info1[3];
+        if (maxleaf >= 7) {
+            int32_t info7[4];
+            jl_cpuidex(info7, 7, 0);
+            features[2] = info7[1];
+            features[3] = info7[2];
+            features[4] = info7[3];
+        }
+        int32_t infoex0[4];
+        jl_cpuid(infoex0, 0x80000000);
+        uint32_t maxexleaf = infoex0[0];
+        if (maxexleaf >= 0x80000001) {
+            int32_t infoex1[4];
+            jl_cpuid(infoex1, 0x80000001);
+            features[5] = infoex1[2];
+            features[6] = infoex1[3];
+        }
+        if (maxleaf >= 0xd) {
+            int32_t infod[4];
+            jl_cpuidex(infod, 0xd, 0x1);
+            features[7] = infod[0];
+        }
+        if (maxexleaf >= 0x80000008) {
+            int32_t infoex8[4];
+            jl_cpuidex(infoex8, 0x80000008, 0);
+            features[8] = infoex8[1];
+        }
+
+        // Fix up AVX bits to account for OS support and match LLVM model
+        uint64_t xcr0 = 0;
+        const uint32_t avx_mask = (1 << 27) | (1 << 28);
+        bool hasavx = test_all_bits(features[0], avx_mask);
+        if (hasavx) {
+            xcr0 = get_xcr0();
+            hasavx = test_all_bits(xcr0, 0x6);
+        }
+        unset_bits(features, 32 + 27);
+        if (!hasavx)
+            features_disable_avx(features);
+        bool hasavx512save = hasavx && test_all_bits(xcr0, 0xe0);
+        if (!hasavx512save)
+            features_disable_avx512(features);
+        // Ignore feature bits that we are not interested in.
+        mask_features(feature_masks, &features[0]);
+
+        uint32_t cpu;
+        if (vendor == SIG_INTEL) {
+            cpu = uint32_t(get_intel_processor_name(family, model, brand_id, &features[0]));
+        }
+        else if (vendor == SIG_AMD) {
+            cpu = uint32_t(get_amd_processor_name(family, model, &features[0]));
+        }
+        else {
+            cpu = uint32_t(CPU::generic);
+        }
+
+        return std::make_pair(cpu, features);
+    }();
+    return host_cpu;
+}
+
+static inline const CPUSpec<CPU,feature_sz> *find_cpu(uint32_t cpu)
+{
+    return ::find_cpu(cpu, cpus, ncpu_names);
+}
+
+static inline const CPUSpec<CPU,feature_sz> *find_cpu(const char *name)
+{
+    return ::find_cpu(name, cpus, ncpu_names);
+}
+
+static inline const char *find_cpu_name(uint32_t cpu)
+{
+    return ::find_cpu_name(cpu, cpus, ncpu_names);
+}
+
+static inline CPU find_cpu_id(const char *name)
+{
+    return ::find_cpu_id(name, cpus, ncpu_names);
+}
+
+static inline const std::string &host_cpu_name()
+{
+    static std::string name =
+        (CPU)get_host_cpu().first != CPU::generic ?
+        std::string(find_cpu_name(get_host_cpu().first)) :
+        jl_get_cpu_name_llvm();
+    return name;
+}
+
+static inline const char *normalize_cpu_name(const char *name)
+{
+    if (strcmp(name, "atom") == 0)
+        return "bonnell";
+    if (strcmp(name, "slm") == 0)
+        return "silvermont";
+    if (strcmp(name, "glm") == 0)
+        return "goldmont";
+    if (strcmp(name, "corei7") == 0)
+        return "nehalem";
+    if (strcmp(name, "corei7-avx") == 0)
+        return "sandybridge";
+    if (strcmp(name, "core-avx-i") == 0)
+        return "ivybridge";
+    if (strcmp(name, "core-avx2") == 0)
+        return "haswell";
+    if (strcmp(name, "skx") == 0)
+        return "skylake-avx512";
+#ifdef _CPU_X86_
+    if (strcmp(name, "pentium4") == 0)
+        return "generic";
+#else
+    if (strcmp(name, "x86-64") == 0 || strcmp(name, "x86_64") == 0)
+        return "generic";
+#endif
+    return nullptr;
+}
+
+template<size_t n>
+static inline void enable_depends(FeatureList<n> &features)
+{
+    ::enable_depends(features, Feature::deps, sizeof(Feature::deps) / sizeof(FeatureDep));
+}
+
+template<size_t n>
+static inline void disable_depends(FeatureList<n> &features)
+{
+    ::disable_depends(features, Feature::deps, sizeof(Feature::deps) / sizeof(FeatureDep));
+}
+
+static const std::vector<TargetData<feature_sz>> &get_cmdline_targets(void)
+{
+    auto feature_cb = [] (const char *str, size_t len, FeatureList<feature_sz> &list) {
+        auto fbit = find_feature_bit(feature_names, nfeature_names, str, len);
+        if (fbit == (uint32_t)-1)
+            return false;
+        set_bit(list, fbit, true);
+        return true;
+    };
+    auto &targets = ::get_cmdline_targets<feature_sz>(feature_cb);
+    for (auto &t: targets) {
+        if (auto nname = normalize_cpu_name(t.name.c_str())) {
+            t.name = nname;
+        }
+    }
+    return targets;
+}
+
+static std::vector<TargetData<feature_sz>> jit_targets;
+
+static TargetData<feature_sz> arg_target_data(const TargetData<feature_sz> &arg, bool require_host)
+{
+    TargetData<feature_sz> res = arg;
+    const FeatureList<feature_sz> *cpu_features = nullptr;
+    if (res.name == "native") {
+        res.name = host_cpu_name();
+        cpu_features = &get_host_cpu().second;
+    }
+    else if (auto spec = find_cpu(res.name.c_str())) {
+        cpu_features = &spec->features;
+    }
+    else {
+        res.en.flags |= JL_TARGET_UNKNOWN_NAME;
+    }
+    if (cpu_features) {
+        for (size_t i = 0; i < feature_sz; i++) {
+            res.en.features[i] |= (*cpu_features)[i];
+        }
+    }
+    enable_depends(res.en.features);
+    for (size_t i = 0; i < feature_sz; i++)
+        res.en.features[i] &= ~res.dis.features[i];
+    if (require_host) {
+        for (size_t i = 0; i < feature_sz; i++) {
+            res.en.features[i] &= get_host_cpu().second[i];
+        }
+    }
+    disable_depends(res.en.features);
+    if (cpu_features) {
+        // If the base feature if known, fill in the disable features
+        for (size_t i = 0; i < feature_sz; i++) {
+            res.dis.features[i] = feature_masks[i] & ~res.en.features[i];
+        }
+    }
+    return res;
+}
+
+static int max_vector_size(const FeatureList<feature_sz> &features)
+{
+    if (test_nbit(features, Feature::avx512f))
+        return 64;
+    if (test_nbit(features, Feature::avx))
+        return 32;
+    // SSE is required
+    return 16;
+}
+
+static uint32_t sysimg_init_cb(const void *id)
+{
+    // First see what target is requested for the JIT.
+    auto &cmdline = get_cmdline_targets();
+    TargetData<feature_sz> target = arg_target_data(cmdline[0], true);
+    // Then find the best match in the sysimg
+    auto sysimg = deserialize_target_data<feature_sz>((const uint8_t*)id);
+    auto match = match_sysimg_targets(sysimg, target, max_vector_size);
+    // Now we've decided on which sysimg version to use.
+    // Make sure the JIT target is compatible with it and save the JIT target.
+    if (match.vreg_size != max_vector_size(target.en.features) &&
+        (sysimg[match.best_idx].en.flags & JL_TARGET_VEC_CALL)) {
+        if (match.vreg_size < 64) {
+            features_disable_avx512(target.en.features);
+        }
+        if (match.vreg_size < 32) {
+            features_disable_avx(target.en.features);
+        }
+    }
+    jit_targets.push_back(std::move(target));
+    return match.best_idx;
+}
+
+static void ensure_jit_target(bool imaging)
+{
+    auto &cmdline = get_cmdline_targets();
+    check_cmdline(cmdline, imaging);
+    if (!jit_targets.empty())
+        return;
+    for (auto &arg: cmdline) {
+        auto data = arg_target_data(arg, jit_targets.empty());
+        jit_targets.push_back(std::move(data));
+    }
+    auto ntargets = jit_targets.size();
+    // Now decide the clone condition.
+    for (size_t i = 1; i < ntargets; i++) {
+        auto &t = jit_targets[i];
+        if (t.en.flags & JL_TARGET_CLONE_ALL)
+            continue;
+        // The most useful one in general...
+        t.en.flags |= JL_TARGET_CLONE_LOOP;
+        auto &features0 = jit_targets[t.base].en.features;
+        // Special case for KNL since it's so different
+        if (!(t.dis.flags & JL_TARGET_CLONE_ALL)) {
+            if (t.name == "knl" && jit_targets[t.base].name != "knl") {
+                t.en.flags |= JL_TARGET_CLONE_ALL;
+                break;
+            }
+        }
+        static constexpr uint32_t clone_math[] = {Feature::fma, Feature::fma4};
+        static constexpr uint32_t clone_simd[] = {Feature::sse3, Feature::ssse3,
+                                                  Feature::sse41, Feature::sse42,
+                                                  Feature::avx, Feature::avx2,
+                                                  Feature::sse4a, Feature::avx512f,
+                                                  Feature::avx512dq, Feature::avx512ifma,
+                                                  Feature::avx512pf, Feature::avx512er,
+                                                  Feature::avx512cd, Feature::avx512bw,
+                                                  Feature::avx512vl, Feature::avx512vbmi,
+                                                  Feature::avx512vpopcntdq};
+        for (auto fe: clone_math) {
+            if (!test_nbit(features0, fe) && test_nbit(t.en.features, fe)) {
+                t.en.flags |= JL_TARGET_CLONE_MATH;
+                break;
+            }
+        }
+        for (auto fe: clone_simd) {
+            if (!test_nbit(features0, fe) && test_nbit(t.en.features, fe)) {
+                t.en.flags |= JL_TARGET_CLONE_SIMD;
+                break;
+            }
+        }
+    }
+}
+
+static std::pair<std::string,std::vector<std::string>>
+get_llvm_target_noext(const TargetData<feature_sz> &data)
+{
+    std::string name = data.name;
+    while (auto *spec = find_cpu(name.c_str())) {
+        if (spec->llvmver <= JL_LLVM_VERSION)
+            break;
+        name = find_cpu_name((uint32_t)spec->fallback);
+    }
+    std::vector<std::string> features;
+    for (auto &fename: feature_names) {
+        if (fename.llvmver > JL_LLVM_VERSION)
+            continue;
+        if (test_nbit(data.en.features, fename.bit)) {
+            features.insert(features.begin(), std::string("+") + fename.name);
+        }
+        else if (test_nbit(data.dis.features, fename.bit)) {
+            features.push_back(std::string("-") + fename.name);
+        }
+    }
+    features.push_back("+sse2");
+#if JL_LLVM_VERSION < 50000
+#  ifdef _CPU_X86_
+    // LLVM has bug on < 5.0 when using avx in 32bit mode.
+    features.push_back("-avx");
+#  endif
+    // Scatter-gatter can't handle address space on < 5.0
+    // This is a base requirement for AVX512 so we have to turn all AVX512 features off
+    // Gatter is available in AVX2 too but fortunately LLVM doesn't use them.
+    features.push_back("-avx512f");
+    features.push_back("-avx512dq");
+#endif
+    return std::make_pair(std::move(name), std::move(features));
+}
+
+static std::pair<std::string,std::vector<std::string>>
+get_llvm_target_vec(const TargetData<feature_sz> &data)
+{
+    auto res0 = get_llvm_target_noext(data);
+    append_ext_features(res0.second, data.ext_features);
+    return res0;
+}
+
+static std::pair<std::string,std::string>
+get_llvm_target_str(const TargetData<feature_sz> &data)
+{
+    auto res0 = get_llvm_target_noext(data);
+    auto features = join_feature_strs(res0.second);
+    append_ext_features(features, data.ext_features);
+    return std::make_pair(std::move(res0.first), std::move(features));
+}
+
+}
+
+using namespace X86;
+
+JL_DLLEXPORT void jl_dump_host_cpu(void)
+{
+    dump_cpu_spec(get_host_cpu().first, get_host_cpu().second, feature_names, nfeature_names,
+                  cpus, ncpu_names);
+}
+
+JL_DLLEXPORT jl_value_t *jl_get_cpu_name(void)
+{
+    return jl_cstr_to_string(host_cpu_name().c_str());
+}
+
+jl_sysimg_fptrs_t jl_init_processor_sysimg(void *hdl)
+{
+    if (!jit_targets.empty())
+        jl_error("JIT targets already initialized");
+    return parse_sysimg(hdl, sysimg_init_cb);
+}
+
+std::pair<std::string,std::vector<std::string>> jl_get_llvm_target(bool imaging, uint32_t &flags)
+{
+    ensure_jit_target(imaging);
+    flags = jit_targets[0].en.flags;
+    return get_llvm_target_vec(jit_targets[0]);
+}
+
+const std::pair<std::string,std::string> &jl_get_llvm_disasm_target(void)
+{
+    static const auto res = get_llvm_target_str(TargetData<feature_sz>{"generic", "",
+            {feature_masks, 0}, {{}, 0}, 0});
+    return res;
+}
+
+std::vector<jl_target_spec_t> jl_get_llvm_clone_targets(void)
+{
+    if (jit_targets.empty())
+        jl_error("JIT targets not initialized");
+    std::vector<jl_target_spec_t> res;
+    for (auto &target: jit_targets) {
+        auto features_en = target.en.features;
+        auto features_dis = target.dis.features;
+        for (auto &fename: feature_names) {
+            if (fename.llvmver > JL_LLVM_VERSION) {
+                unset_bits(features_en, fename.bit);
+                unset_bits(features_dis, fename.bit);
+            }
+        }
+        X86::disable_depends(features_en);
+        jl_target_spec_t ele;
+        std::tie(ele.cpu_name, ele.cpu_features) = get_llvm_target_str(target);
+        ele.data = serialize_target_data(target.name.c_str(), features_en, features_dis,
+                                         target.ext_features.c_str());
+        ele.flags = target.en.flags;
+        ele.base = target.base;
+        res.push_back(ele);
+    }
+    return res;
+}
+
+extern "C" int jl_test_cpu_feature(jl_cpu_feature_t feature)
+{
+    if (feature >= 32 * feature_sz)
+        return 0;
+    return test_nbit(&get_host_cpu().second[0], feature);
+}
+
+// -- set/clear the FZ/DAZ flags on x86 & x86-64 --
+
+// Cache of information recovered from `cpuid` since executing `cpuid` it at runtime is slow.
+static uint32_t subnormal_flags = [] {
+    int32_t info[4];
+    jl_cpuid(info, 0);
+    if (info[0] >= 1) {
+        jl_cpuid(info, 1);
+        if (info[3] & (1 << 26)) {
+            // SSE2 supports both FZ and DAZ
+            return 0x00008040;
+        }
+        else if (info[3] & (1 << 25)) {
+            // SSE supports only the FZ flag
+            return 0x00008000;
+        }
+    }
+    return 0;
+}();
+
+// Returns non-zero if subnormals go to 0; zero otherwise.
+extern "C" JL_DLLEXPORT int32_t jl_get_zero_subnormals(void)
+{
+    return _mm_getcsr() & subnormal_flags;
+}
+
+// Return zero on success, non-zero on failure.
+extern "C" JL_DLLEXPORT int32_t jl_set_zero_subnormals(int8_t isZero)
+{
+    uint32_t flags = subnormal_flags;
+    if (flags) {
+        uint32_t state = _mm_getcsr();
+        if (isZero)
+            state |= flags;
+        else
+            state &= ~flags;
+        _mm_setcsr(state);
+        return 0;
+    }
+    else {
+        // Report a failure only if user is trying to enable FTZ/DAZ.
+        return isZero;
+    }
+}
diff --git a/src/runtime_ccall.cpp b/src/runtime_ccall.cpp
index 49a0640943..bbc5d34b1b 100644
--- a/src/runtime_ccall.cpp
+++ b/src/runtime_ccall.cpp
@@ -7,6 +7,7 @@
 #include <llvm/Support/Host.h>
 #include "julia.h"
 #include "julia_internal.h"
+#include "processor.h"
 #include "julia_assert.h"
 
 using namespace llvm;
@@ -173,11 +174,41 @@ void *jl_load_and_lookup(const char *f_lib, const char *f_name, void **hnd)
 }
 
 // miscellany
-extern "C" JL_DLLEXPORT
-jl_value_t *jl_get_cpu_name(void)
+std::string jl_get_cpu_name_llvm(void)
+{
+    return llvm::sys::getHostCPUName().str();
+}
+
+std::string jl_get_cpu_features_llvm(void)
 {
-    StringRef HostCPUName = llvm::sys::getHostCPUName();
-    return jl_pchar_to_string(HostCPUName.data(), HostCPUName.size());
+    StringMap<bool> HostFeatures;
+    llvm::sys::getHostCPUFeatures(HostFeatures);
+    std::string attr;
+    for (auto &ele: HostFeatures) {
+        if (ele.getValue()) {
+            if (!attr.empty()) {
+                attr.append(",+");
+            }
+            else {
+                attr.append("+");
+            }
+            attr.append(ele.getKey().str());
+        }
+    }
+    // Explicitly disabled features need to be added at the end so that
+    // they are not reenabled by other features that implies them by default.
+    for (auto &ele: HostFeatures) {
+        if (!ele.getValue()) {
+            if (!attr.empty()) {
+                attr.append(",-");
+            }
+            else {
+                attr.append("-");
+            }
+            attr.append(ele.getKey().str());
+        }
+    }
+    return attr;
 }
 
 extern "C" JL_DLLEXPORT
-- 
2.14.2

